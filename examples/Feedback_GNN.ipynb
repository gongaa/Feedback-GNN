{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "041204d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available : 1\n",
      "Only GPU number 0 used.\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # INFO, WARNING messages are not printed\n",
    "import tensorflow as tf\n",
    "import time # for throughput measurements\n",
    "\n",
    "# Configure the notebook to use only a single GPU and allocate only as much memory as needed\n",
    "# For more details, see https://www.tensorflow.org/guide/gpu\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print('Number of GPUs available :', len(gpus))\n",
    "if gpus:\n",
    "    gpu_num = 0 # Number of the GPU to be used\n",
    "    try:\n",
    "        #tf.config.set_visible_devices([], 'GPU')\n",
    "        tf.config.set_visible_devices(gpus[gpu_num], 'GPU')\n",
    "        print('Only GPU number', gpu_num, 'used.')\n",
    "        tf.config.experimental.set_memory_growth(gpus[gpu_num], True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# uninstall sionna first\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(str(Path('..')))\n",
    "\n",
    "from sionna.fec.ldpc import QLDPCBPDecoder, readAlist, Feedback_GNN, GNN_BP4, save_weights, load_weights \n",
    "from sionna.fec.ldpc import Sandwich_BP_GNN_Evaluation_Model, First_Stage_BP_Model, Second_Stage_GNN_BP_Model\n",
    "from sionna.fec.ldpc import *\n",
    "from sionna.utils import BinarySource \n",
    "from sionna.utils.metrics import count_block_errors\n",
    "from sionna.channel import Pauli\n",
    "from sionna.utils.plotting import PlotBER\n",
    "\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from sionna.utils.metrics import compute_bler\n",
    "from sionna.fec.utils import int_mod_2\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fd07e9",
   "metadata": {},
   "source": [
    "# Train feedback GNN on mixed data (hard samples repeat 50 times) for the [[1270,28]] code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcea4c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datase size tf.Tensor(1307084, shape=(), dtype=int64)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e7a6c8112c7419fb2bad4354615537c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13071 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f9e6c6e5430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f9e6c6e5430> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Iteration 500/13071. Current loss: 0.012896 bler: 0.0300 flagged bler: 0.0300\n",
      "Iteration 1000/13071. Current loss: 0.011347 bler: 0.0300 flagged bler: 0.0300\n",
      "Iteration 1500/13071. Current loss: 0.007706 bler: 0.0200 flagged bler: 0.0200\n",
      "Iteration 2000/13071. Current loss: 0.012872 bler: 0.0200 flagged bler: 0.0200\n",
      "Iteration 2500/13071. Current loss: 0.004619 bler: 0.0100 flagged bler: 0.0100\n",
      "Iteration 3000/13071. Current loss: 0.004173 bler: 0.0000 flagged bler: 0.0000\n",
      "Iteration 3500/13071. Current loss: 0.000772 bler: 0.0000 flagged bler: 0.0000\n",
      "Iteration 4000/13071. Current loss: 0.010500 bler: 0.0100 flagged bler: 0.0100\n",
      "Iteration 4500/13071. Current loss: 0.009045 bler: 0.0300 flagged bler: 0.0300\n",
      "Iteration 5000/13071. Current loss: 0.003627 bler: 0.0100 flagged bler: 0.0100\n",
      "Iteration 5500/13071. Current loss: 0.004644 bler: 0.0000 flagged bler: 0.0000\n",
      "Iteration 6000/13071. Current loss: 0.002655 bler: 0.0000 flagged bler: 0.0000\n",
      "Iteration 6500/13071. Current loss: 0.003415 bler: 0.0000 flagged bler: 0.0000\n",
      "Iteration 7000/13071. Current loss: 0.003396 bler: 0.0000 flagged bler: 0.0000\n",
      "Iteration 7500/13071. Current loss: 0.003884 bler: 0.0000 flagged bler: 0.0000\n",
      "Iteration 8000/13071. Current loss: 0.002959 bler: 0.0000 flagged bler: 0.0000\n",
      "Iteration 8500/13071. Current loss: 0.001788 bler: 0.0000 flagged bler: 0.0000\n",
      "Iteration 9000/13071. Current loss: 0.002462 bler: 0.0000 flagged bler: 0.0000\n",
      "Iteration 9500/13071. Current loss: 0.002552 bler: 0.0100 flagged bler: 0.0100\n",
      "Iteration 10000/13071. Current loss: 0.002008 bler: 0.0000 flagged bler: 0.0000\n",
      "Iteration 10500/13071. Current loss: 0.000627 bler: 0.0000 flagged bler: 0.0000\n",
      "Iteration 11000/13071. Current loss: 0.004977 bler: 0.0200 flagged bler: 0.0200\n",
      "Iteration 11500/13071. Current loss: 0.008445 bler: 0.0200 flagged bler: 0.0200\n",
      "Iteration 12000/13071. Current loss: 0.003069 bler: 0.0000 flagged bler: 0.0000\n",
      "Iteration 12500/13071. Current loss: 0.002050 bler: 0.0000 flagged bler: 0.0000\n",
      "Iteration 13000/13071. Current loss: 0.003414 bler: 0.0100 flagged bler: 0.0100\n"
     ]
    }
   ],
   "source": [
    "GHP_n1270_k28 = create_QC_GHP_codes(127, np.array([[0,-1,51,52,-1],[-1,0,-1,111,20],[0,-1,98,-1,122],[0,80,-1,119,-1],[-1,0,5,-1,106]]), [0,1,7], name=\"GHP_n1270_k28\") # 16 <= d <= 46\n",
    "code = GHP_n1270_k28\n",
    "num_iter1 = tf.constant(64)\n",
    "num_iter2 = tf.constant(16)\n",
    "\n",
    "factor1 = tf.constant(1.0)\n",
    "factor2 = tf.constant(1.0)\n",
    "\n",
    "decoder1 = QLDPCBPDecoder(code=code, num_iter=num_iter1, normalization_factor=factor1, cn_type=\"boxplus-phi\", trainable=False, stage_one=True)\n",
    "decoder2 = QLDPCBPDecoder(code=code, num_iter=num_iter2, normalization_factor=factor2, cn_type=\"boxplus-phi\", trainable=False, stage_two=True)\n",
    "# stage-two BP decoder does some extra calculations for multi-loss calculation\n",
    "\n",
    "bs = tf.constant(100)\n",
    "n = tf.constant(code.N)\n",
    "cn_z = tf.constant(code.hz.shape[0])\n",
    "cn_x = tf.constant(code.hx.shape[0])\n",
    "\n",
    "G = Feedback_GNN(code=code, \n",
    "                 num_msg_dims=tf.constant(20),\n",
    "                 num_hidden_units=tf.constant(40),\n",
    "                 num_mlp_layers=2,\n",
    "                 reduce_op=\"mean\",      # can choose from [sum, mean, max, min]\n",
    "                 activation=\"tanh\",\n",
    "                 use_bias=True)\n",
    "\n",
    "# Split into two models so that the first stage BP decoding can be done in XLA mode.\n",
    "model_stage_one  = First_Stage_BP_Model(code, decoder1)\n",
    "# The implementation of second stage involves TensorArray, taking gradient is not supported by XLA.\n",
    "model_stage_two = Second_Stage_GNN_BP_Model(code, G, decoder2, num_iter=num_iter2)\n",
    "\n",
    "dataset_x = tf.data.Dataset.from_tensor_slices(np.load(\"../sionna/fec/ldpc/datasets/n1270_k28_wt_10_80_x_all.npy\"))\n",
    "dataset_z = tf.data.Dataset.from_tensor_slices(np.load(\"../sionna/fec/ldpc/datasets/n1270_k28_wt_10_80_z_all.npy\"))                                              \n",
    "\n",
    "\n",
    "dataset = tf.data.Dataset.zip((dataset_x, dataset_z))\n",
    "dataset_size = dataset.cardinality()\n",
    "print(\"datase size\", dataset_size)\n",
    "dataset = dataset.shuffle(dataset_size, reshuffle_each_iteration=True)\n",
    "bs      = 100\n",
    "repeat  = 1\n",
    "dataset = dataset.repeat(repeat).batch(bs)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "it = tf.constant(0)\n",
    "decay_steps = int(dataset_size * repeat / bs) + 1\n",
    "# We only train for one epoch. If train multiple epochs, better use cosine scheduing.\n",
    "# decayed_lr = tf.keras.optimizers.schedules.CosineDecay(2e-4, decay_steps)\n",
    "# optimizer = tf.keras.optimizers.Adam(decayed_lr)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-4) \n",
    "\n",
    "clip_value_grad = 10 # gradient clipping for stable training convergence\n",
    "for x,z in tqdm(dataset):\n",
    "    it += 1\n",
    "    h_vn, logit_hx_perp, logit_hz_perp = model_stage_one(x, z)\n",
    "    with tf.GradientTape() as tape:\n",
    "        s_hat, b_hat, loss = model_stage_two(x, z, h_vn, logit_hx_perp, logit_hz_perp)\n",
    "        \n",
    "    flagged_bler = compute_bler(tf.zeros_like(s_hat), s_hat)\n",
    "    bler = compute_bler(tf.zeros_like(b_hat), b_hat)\n",
    "    if it % 500 == 0:\n",
    "        print(f\"Iteration {it}/{decay_steps}. Current loss: {loss:3f} bler: {bler:.4f} flagged bler: {flagged_bler:.4f}\".format())\n",
    "\n",
    "    grads = tape.gradient(loss, model_stage_two.trainable_variables)\n",
    "    grads = [tf.clip_by_value(grad, -clip_value_grad, clip_value_grad) for grad in grads]\n",
    "    optimizer.apply_gradients(zip(grads, model_stage_two.trainable_weights))    \n",
    "\n",
    "save_weights(G, f\"../sionna/fec/ldpc/weights/feedback_GNN_n1270_k28_wt_10_80_iter_64_16_mixed.npy\") # change name to prevent overwriting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45c110e",
   "metadata": {},
   "source": [
    "# Load the trained GNN model and evaluate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65aef733",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "GHP_n1270_k28 = create_QC_GHP_codes(127, np.array([[0,-1,51,52,-1],[-1,0,-1,111,20],[0,-1,98,-1,122],[0,80,-1,119,-1],[-1,0,5,-1,106]]), [0,1,7], name=\"GHP_n1270_k28\") # 16 <= d <= 46\n",
    "code = GHP_n1270_k28\n",
    "\n",
    "ber_plot = PlotBER()\n",
    "\n",
    "bs = tf.constant(5000)\n",
    "n = tf.constant(code.N)\n",
    "cn_z = tf.constant(code.hz.shape[0])\n",
    "cn_x = tf.constant(code.hx.shape[0])\n",
    "\n",
    "G = Feedback_GNN(code=code, \n",
    "                 num_msg_dims=tf.constant(20),\n",
    "                 num_hidden_units=tf.constant(40),\n",
    "                 num_mlp_layers=2,\n",
    "                 reduce_op=\"mean\",     \n",
    "                 activation=\"tanh\",\n",
    "                 use_bias=True)\n",
    "# Pass dummy input to the model first.\n",
    "G((tf.zeros((bs, n, 3)), tf.zeros((cn_x, bs)), tf.zeros((cn_z, bs)), \n",
    "                  tf.zeros((cn_x, bs)), tf.zeros((cn_z, bs))))\n",
    "# Then load the stored weights.\n",
    "load_weights(G, f\"../sionna/fec/ldpc/weights/feedback_GNN_n1270_k28_wt_10_80_iter_64_16_mixed.npy\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c11db80",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        p |    Flagged |       BLER | flag errors | block errors |  num blocks | runtime [s] |    status\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "     0.14 | 3.9640e-01 | 3.9640e-01 |        1982 |         1982 |        5000 |        12.9 |reached target block errors\n",
      "     0.13 | 1.3880e-01 | 1.3880e-01 |         694 |          694 |        5000 |         0.8 |reached target block errors\n",
      "     0.12 | 2.7600e-02 | 2.7600e-02 |         138 |          138 |        5000 |         0.8 |reached target block errors\n",
      "     0.11 | 3.7000e-03 | 3.7000e-03 |         111 |          111 |       30000 |         4.8 |reached target block errors\n",
      "      0.1 | 3.6786e-04 | 3.6786e-04 |         103 |          103 |      280000 |        44.9 |reached target block errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(5,), dtype=float64, numpy=\n",
       " array([3.96400000e-01, 1.38800000e-01, 2.76000000e-02, 3.70000000e-03,\n",
       "        3.67857143e-04])>,\n",
       " <tf.Tensor: shape=(5,), dtype=float64, numpy=\n",
       " array([3.96400000e-01, 1.38800000e-01, 2.76000000e-02, 3.70000000e-03,\n",
       "        3.67857143e-04])>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_iter1 = tf.constant(64)\n",
    "num_iter2 = tf.constant(16)\n",
    "factor1 = tf.constant(1.0)\n",
    "factor2 = tf.constant(1.0)\n",
    "\n",
    "decoder1 = QLDPCBPDecoder(code=code, num_iter=num_iter1, normalization_factor=factor1, cn_type=\"boxplus-phi\", trainable=False, stage_one=True)\n",
    "decoder2 = QLDPCBPDecoder(code=code, num_iter=num_iter2, normalization_factor=factor2, cn_type=\"boxplus-phi\", trainable=False, stage_one=True)\n",
    "\n",
    "\n",
    "model_eval = Sandwich_BP_GNN_Evaluation_Model(code, [decoder1]+[decoder2]*3, [G]*3, num_layers=4)\n",
    "p = np.arange(0.10, 0.141, 0.01)[::-1]\n",
    "ber_plot.simulate(model_eval,\n",
    "              ebno_dbs=p,\n",
    "              batch_size=bs,\n",
    "              num_target_block_errors=100, # stop sim after 100 logical errors\n",
    "              legend=f\"feedback GNN {factor1.numpy():.2f} (G,G,G)\",\n",
    "              soft_estimates=True,\n",
    "              max_mc_iter=6000,\n",
    "              early_stop=True, # stop simulation if no error has been detected at current SNR point\n",
    "              add_bler=True,   # logical error rate\n",
    "              show_fig=False,  # do not show the figure after all results are simulated\n",
    "              qldpc=True,      # can see number of flagged errors\n",
    "              forward_keyboard_interrupt=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdc39fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sandwich_bp_gnn__evaluation__model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " binary_source (BinarySource  multiple                 0 (unused)\n",
      " )                                                               \n",
      "                                                                 \n",
      " pauli (Pauli)               multiple                  0         \n",
      "                                                                 \n",
      " qldpcbp_decoder (QLDPCBPDec  multiple                 0         \n",
      " oder)                                                           \n",
      "                                                                 \n",
      " qldpcbp_decoder_1 (QLDPCBPD  multiple                 0         \n",
      " ecoder)                                                         \n",
      "                                                                 \n",
      " feedback_gnn (Feedback_GNN)  multiple                 3923      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,923\n",
      "Trainable params: 3,923\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_eval.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a43db7",
   "metadata": {},
   "source": [
    "# [[882, 24]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85f4dd50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datase size tf.Tensor(1287116, shape=(), dtype=int64)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a227330137a94390a48feb26a0600a2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12872 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 500/12872. Current loss: 0.014715 bler: 0.0100 flagged bler: 0.0100\n",
      "Iteration 1000/12872. Current loss: 0.013874 bler: 0.0300 flagged bler: 0.0300\n",
      "Iteration 1500/12872. Current loss: 0.006196 bler: 0.0000 flagged bler: 0.0000\n",
      "Iteration 2000/12872. Current loss: 0.007878 bler: 0.0100 flagged bler: 0.0100\n",
      "Iteration 2500/12872. Current loss: 0.006150 bler: 0.0100 flagged bler: 0.0100\n",
      "Iteration 3000/12872. Current loss: 0.003681 bler: 0.0000 flagged bler: 0.0000\n",
      "Iteration 3500/12872. Current loss: 0.004665 bler: 0.0100 flagged bler: 0.0100\n",
      "Iteration 4000/12872. Current loss: 0.011738 bler: 0.0200 flagged bler: 0.0200\n",
      "Iteration 4500/12872. Current loss: 0.007271 bler: 0.0200 flagged bler: 0.0200\n",
      "Iteration 5000/12872. Current loss: 0.007780 bler: 0.0100 flagged bler: 0.0100\n",
      "Iteration 5500/12872. Current loss: 0.005075 bler: 0.0000 flagged bler: 0.0000\n",
      "Iteration 6000/12872. Current loss: 0.006377 bler: 0.0000 flagged bler: 0.0000\n",
      "Iteration 6500/12872. Current loss: 0.007058 bler: 0.0200 flagged bler: 0.0200\n",
      "Iteration 7000/12872. Current loss: 0.008673 bler: 0.0200 flagged bler: 0.0200\n",
      "Iteration 7500/12872. Current loss: 0.004438 bler: 0.0100 flagged bler: 0.0100\n",
      "Iteration 8000/12872. Current loss: 0.005134 bler: 0.0100 flagged bler: 0.0100\n",
      "Iteration 8500/12872. Current loss: 0.001944 bler: 0.0000 flagged bler: 0.0000\n",
      "Iteration 9000/12872. Current loss: 0.010747 bler: 0.0200 flagged bler: 0.0200\n",
      "Iteration 9500/12872. Current loss: 0.005037 bler: 0.0200 flagged bler: 0.0200\n",
      "Iteration 10000/12872. Current loss: 0.005503 bler: 0.0100 flagged bler: 0.0100\n",
      "Iteration 10500/12872. Current loss: 0.009584 bler: 0.0200 flagged bler: 0.0200\n",
      "Iteration 11000/12872. Current loss: 0.004109 bler: 0.0000 flagged bler: 0.0000\n",
      "Iteration 11500/12872. Current loss: 0.013516 bler: 0.0100 flagged bler: 0.0100\n",
      "Iteration 12000/12872. Current loss: 0.009990 bler: 0.0200 flagged bler: 0.0200\n",
      "Iteration 12500/12872. Current loss: 0.006477 bler: 0.0100 flagged bler: 0.0100\n"
     ]
    }
   ],
   "source": [
    "GHP_n882_k24 = create_QC_GHP_codes(63, create_cyclic_permuting_matrix(7, [27,54,0]), [0,1,6]) # 18 <= d <= 24\n",
    "code = GHP_n882_k24\n",
    "\n",
    "num_iter1 = tf.constant(64)   # when training easy + hard examples\n",
    "num_iter2 = tf.constant(16)\n",
    "factor = tf.constant(1.0)\n",
    "decoder1 = QLDPCBPDecoder(code=code, num_iter=num_iter1, normalization_factor=factor, cn_type=\"boxplus-phi\", trainable=False, stage_one=True)\n",
    "decoder2 = QLDPCBPDecoder(code=code, num_iter=num_iter2, normalization_factor=factor, cn_type=\"boxplus-phi\", trainable=True, stage_two=True)\n",
    "G = Feedback_GNN(code=code, \n",
    "                 num_msg_dims=tf.constant(20),\n",
    "                 num_hidden_units=tf.constant(40),\n",
    "                 num_mlp_layers=2,\n",
    "                 reduce_op=\"mean\",\n",
    "                 activation=\"tanh\",\n",
    "                 use_bias=True)\n",
    "\n",
    "model_stage_one  = First_Stage_BP_Model(code, decoder1)\n",
    "model_stage_two = Second_Stage_GNN_BP_Model(code, G, decoder2, num_iter=num_iter2)\n",
    "\n",
    "dataset_x = tf.data.Dataset.from_tensor_slices(np.load(\"../sionna/fec/ldpc/datasets/n882_k24_wt_4_60_x_all.npy\"))\n",
    "dataset_z = tf.data.Dataset.from_tensor_slices(np.load(\"../sionna/fec/ldpc/datasets/n882_k24_wt_4_60_z_all.npy\"))  \n",
    "\n",
    "dataset = tf.data.Dataset.zip((dataset_x, dataset_z))\n",
    "dataset_size = dataset.cardinality()\n",
    "print(\"datase size\", dataset_size)\n",
    "dataset = dataset.shuffle(dataset_size, reshuffle_each_iteration=True)\n",
    "bs      = 100\n",
    "repeat  = 1\n",
    "dataset = dataset.repeat(repeat).batch(bs)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "it = tf.constant(0)\n",
    "decay_steps = int(dataset_size * repeat / bs) + 1\n",
    "\n",
    "# decayed_lr = tf.keras.optimizers.schedules.CosineDecay(1e-4, decay_steps) \n",
    "# optimizer = tf.keras.optimizers.Adam(decayed_lr)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-4)                \n",
    "\n",
    "\n",
    "clip_value_grad = 10 # gradient clipping for stable training convergence\n",
    "for x,z in tqdm(dataset):\n",
    "    it += 1\n",
    "    h_vn, logit_hx_perp, logit_hz_perp = model_stage_one(x, z)\n",
    "    with tf.GradientTape() as tape:\n",
    "        s_hat, b_hat, loss = model_stage_two(x, z, h_vn, logit_hx_perp, logit_hz_perp)\n",
    "        \n",
    "    flagged_bler = compute_bler(tf.zeros_like(s_hat), s_hat)\n",
    "    bler = compute_bler(tf.zeros_like(b_hat), b_hat)\n",
    "    if it % 500 == 0:\n",
    "        print(f\"Iteration {it}/{decay_steps}. Current loss: {loss:3f} bler: {bler:.4f} flagged bler: {flagged_bler:.4f}\".format())\n",
    "\n",
    "    grads = tape.gradient(loss, model_stage_two.trainable_variables)\n",
    "    grads = [tf.clip_by_value(grad, -clip_value_grad, clip_value_grad) for grad in grads]\n",
    "    optimizer.apply_gradients(zip(grads, model_stage_two.trainable_weights))    \n",
    "\n",
    "save_weights(G, f\"../sionna/fec/ldpc/weights/feedback_GNN_n882_k24_wt_4_60_iter_64_16_mixed.npy\") # change name to prevent overwriting\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a499b2b0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "GHP_n882_k24 = create_QC_GHP_codes(63, create_cyclic_permuting_matrix(7, [27,54,0]), [0,1,6]) # 18 <= d <= 24\n",
    "code = GHP_n882_k24\n",
    "\n",
    "ber_plot = PlotBER()\n",
    "\n",
    "bs = tf.constant(5000)\n",
    "n = tf.constant(code.N)\n",
    "cn_z = tf.constant(code.hz.shape[0])\n",
    "cn_x = tf.constant(code.hx.shape[0])\n",
    "\n",
    "G = Feedback_GNN(code=code, \n",
    "                 num_msg_dims=tf.constant(20),\n",
    "                 num_hidden_units=tf.constant(40),\n",
    "                 num_mlp_layers=2,\n",
    "                 reduce_op=\"mean\",     \n",
    "                 activation=\"tanh\",\n",
    "                 use_bias=True)\n",
    "G((tf.zeros((bs, n, 3)), tf.zeros((cn_x, bs)), tf.zeros((cn_z, bs)), \n",
    "                  tf.zeros((cn_x, bs)), tf.zeros((cn_z, bs))))\n",
    "load_weights(G, f\"../sionna/fec/ldpc/weights/feedback_GNN_n882_k24_wt_4_60_iter_64_16_mixed.npy\")   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "588445a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        p |    Flagged |       BLER | flag errors | block errors |  num blocks | runtime [s] |    status\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "     0.14 | 4.8340e-01 | 4.8340e-01 |        2417 |         2417 |        5000 |        11.5 |reached target block errors\n",
      "     0.13 | 2.3360e-01 | 2.3360e-01 |        1168 |         1168 |        5000 |         0.5 |reached target block errors\n",
      "     0.12 | 7.8400e-02 | 7.8400e-02 |         392 |          392 |        5000 |         0.5 |reached target block errors\n",
      "     0.11 | 2.0000e-02 | 2.0000e-02 |         100 |          100 |        5000 |         0.5 |reached target block errors\n",
      "      0.1 | 3.0000e-03 | 3.0000e-03 |         105 |          105 |       35000 |         3.4 |reached target block errors\n",
      "     0.09 | 4.4889e-04 | 4.4889e-04 |         101 |          101 |      225000 |        21.6 |reached target block errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(6,), dtype=float64, numpy=\n",
       " array([4.83400000e-01, 2.33600000e-01, 7.84000000e-02, 2.00000000e-02,\n",
       "        3.00000000e-03, 4.48888889e-04])>,\n",
       " <tf.Tensor: shape=(6,), dtype=float64, numpy=\n",
       " array([4.83400000e-01, 2.33600000e-01, 7.84000000e-02, 2.00000000e-02,\n",
       "        3.00000000e-03, 4.48888889e-04])>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_iter1 = tf.constant(64)\n",
    "num_iter2 = tf.constant(16)\n",
    "factor1 = tf.constant(1.0)\n",
    "factor2 = tf.constant(1.0)\n",
    "\n",
    "decoder1 = QLDPCBPDecoder(code=code, num_iter=num_iter1, normalization_factor=factor1, cn_type=\"boxplus-phi\", trainable=False, stage_one=True)\n",
    "decoder2 = QLDPCBPDecoder(code=code, num_iter=num_iter2, normalization_factor=factor2, cn_type=\"boxplus-phi\", trainable=False, stage_one=True)\n",
    "\n",
    "model_eval = Sandwich_BP_GNN_Evaluation_Model(code, [decoder1]+[decoder2]*3, [G]*3, num_layers=4)\n",
    "p = np.arange(0.09, 0.141, 0.01)[::-1]\n",
    "ber_plot.simulate(model_eval,\n",
    "              ebno_dbs=p,\n",
    "              batch_size=bs,\n",
    "              num_target_block_errors=100, # stop sim after 2000 bit errors\n",
    "              legend=f\"feedback GNN {factor1.numpy():.2f} (G,G,G)\",\n",
    "              soft_estimates=True,\n",
    "              max_mc_iter=6000,\n",
    "              early_stop=True, # stop simulation if no error has been detected at current SNR point\n",
    "              add_bler=True, # in case BLER is also interesting\n",
    "              show_fig=False, # we show the figure after all results are simulated\n",
    "              qldpc=True,\n",
    "              forward_keyboard_interrupt=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
