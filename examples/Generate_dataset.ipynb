{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de94da4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available : 1\n",
      "Only GPU number 0 used.\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # INFO, WARNING messages are not printed\n",
    "import tensorflow as tf\n",
    "import time # for throughput measurements\n",
    "\n",
    "# Configure the notebook to use only a single GPU and allocate only as much memory as needed\n",
    "# For more details, see https://www.tensorflow.org/guide/gpu\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print('Number of GPUs available :', len(gpus))\n",
    "if gpus:\n",
    "    gpu_num = 0 # Number of the GPU to be used\n",
    "    try:\n",
    "        #tf.config.set_visible_devices([], 'GPU')\n",
    "        tf.config.set_visible_devices(gpus[gpu_num], 'GPU')\n",
    "        print('Only GPU number', gpu_num, 'used.')\n",
    "        tf.config.experimental.set_memory_growth(gpus[gpu_num], True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# uninstall sionna first\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(str(Path('..')))\n",
    "\n",
    "from sionna.fec.ldpc import *\n",
    "from sionna.utils import BinarySource \n",
    "from sionna.utils.metrics import count_block_errors\n",
    "from sionna.channel import Pauli\n",
    "from sionna.utils.plotting import PlotBER\n",
    "\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from sionna.utils.metrics import compute_bler\n",
    "from sionna.fec.utils import int_mod_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce5a2024",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BP4_Error_Model(tf.keras.Model):\n",
    "# For storing error strings that the BP decoder failed to decode\n",
    "    def __init__(self, code, decoder, num_iter=32, trainable=False, loss_type=\"boxplus-phi\", wt=False):\n",
    "\n",
    "        super().__init__()\n",
    "        \n",
    "        self.k = code.K      \n",
    "        self.n = code.N\n",
    "        self.hx = code.hx\n",
    "        self.hz = code.hz\n",
    "        self.lx = code.lx\n",
    "        self.lz = code.lz\n",
    "        self.hx_perp = code.hx_perp # contains Im(hz.T)\n",
    "        self.hz_perp = code.hz_perp # contains Im(hx.T)\n",
    "        self.code_name = code.name\n",
    "        self.num_checks = code.hx.shape[0] + code.hz.shape[0]\n",
    "        \n",
    "        self.source = BinarySource()\n",
    "        self.channel = Pauli(wt=wt)\n",
    "        self.decoder = decoder\n",
    "\n",
    "        self.num_iter = num_iter\n",
    "        self.trainable = trainable\n",
    "        self.bce = BinaryCrossentropy(from_logits=True)\n",
    "        self.loss_type = loss_type\n",
    "        self.wt = wt\n",
    "           \n",
    "    @tf.function(jit_compile=True, reduce_retracing=True) # XLA mode\n",
    "    def call(self, batch_size, ebno_db):\n",
    "\n",
    "        p = ebno_db\n",
    "\n",
    "        # depolarizing noise\n",
    "        px, py, pz = 2*p/3, p/3, 2*p/3\n",
    "        c_dummy = tf.zeros([batch_size, self.n])\n",
    "        if self.wt: # ebno_db is an integer indicating the weight of the error\n",
    "            noise_x, noise_z = self.channel([c_dummy, None, p])\n",
    "        else:\n",
    "            noise_x, noise_z = self.channel([c_dummy, None, px, py, pz])  # [bs, self.n]\n",
    "        noise_x_T, noise_z_T = tf.transpose(noise_x, (1,0)), tf.transpose(noise_z, (1,0))\n",
    "        noise_x_int = tf.cast(noise_x_T, self.hz.dtype)\n",
    "        noise_z_int = tf.cast(noise_z_T, self.hx.dtype)\n",
    "        syndrome_x = int_mod_2(tf.matmul(self.hx, noise_z_int))\n",
    "        syndrome_z = int_mod_2(tf.matmul(self.hz, noise_x_int))\n",
    "\n",
    "        p0 = 0.05 \n",
    "        llr_ch_x = tf.fill(tf.shape(noise_x), tf.math.log(3.*(1.-p0)/p0))\n",
    "        llr = tf.tile(tf.expand_dims(llr_ch_x, axis=1), multiples=tf.constant([1, 3, 1], tf.int32))\n",
    "        # shape of llr: [bs, 3, self.n]\n",
    "        \n",
    "        x_hat, z_hat = self.decoder((llr, syndrome_x, syndrome_z))\n",
    "        \n",
    "        x_hat = tf.transpose(tf.cast(x_hat, tf.bool), (1,0)) # [self.n, bs]\n",
    "        z_hat = tf.transpose(tf.cast(z_hat, tf.bool), (1,0))\n",
    "\n",
    "        x_diff = tf.cast(tf.math.logical_xor(noise_x_T, x_hat), self.hx_perp.dtype)\n",
    "        z_diff = tf.cast(tf.math.logical_xor(noise_z_T, z_hat), self.hz_perp.dtype)\n",
    "\n",
    "        sx = int_mod_2(tf.matmul(self.hz, x_diff))\n",
    "        sz = int_mod_2(tf.matmul(self.hx, z_diff))\n",
    "        s_hat = tf.concat([sx, sz], axis=0)\n",
    "        s_hat = tf.transpose(s_hat, (1,0))\n",
    "        err = tf.reduce_any(tf.not_equal(tf.zeros_like(s_hat), s_hat), axis=-1)\n",
    "        return noise_x[err], noise_z[err]\n",
    "\n",
    "\n",
    "class Feedback_GNN_Error_Model(tf.keras.Model):\n",
    "# For storing error strings that the (BP, feedback_GNN, BP) decoder failed to decode\n",
    "    def __init__(self, code, decoder1, feedback, decoder2, wt=False, p0=0.05):\n",
    "\n",
    "        super().__init__()\n",
    "        \n",
    "        self.k = code.K      \n",
    "        self.n = code.N\n",
    "        self.hx = code.hx # [cn, n]\n",
    "        self.hz = code.hz\n",
    "        self.lx = code.lx\n",
    "        self.lz = code.lz\n",
    "\n",
    "        self.hx_perp = code.hx_perp\n",
    "        self.hz_perp = code.hz_perp\n",
    "        self.code_name = code.name\n",
    "        self.num_checks = code.hx.shape[0] + code.hz.shape[0]\n",
    "  \n",
    "        self.source = BinarySource()\n",
    "        self.channel = Pauli(wt=wt)\n",
    "        \n",
    "        self.decoder1 = decoder1\n",
    "        self.feedback = feedback\n",
    "        self.decoder2 = decoder2\n",
    "\n",
    "        self.wt = wt\n",
    "        self.p0 = p0\n",
    "        \n",
    "      \n",
    "    @tf.function(jit_compile=True, reduce_retracing=True) # XLA mode during evaluation\n",
    "    def call(self, batch_size, ebno_db):\n",
    "#     def call(self, noise_x, noise_z):\n",
    "\n",
    "        p = ebno_db\n",
    "        c_dummy = tf.zeros([batch_size, self.n])\n",
    "        if self.wt: # p is the weight of the error strings\n",
    "            noise_x, noise_z = self.channel([c_dummy, None, p])\n",
    "        else:\n",
    "            # depolarizing noise\n",
    "            px, py, pz = 2*p/3, p/3, 2*p/3\n",
    "            noise_x, noise_z = self.channel([c_dummy, None, px, py, pz])  # [bs, self.n]\n",
    "            \n",
    "        noise_x_T, noise_z_T = tf.transpose(noise_x, (1,0)), tf.transpose(noise_z, (1,0))\n",
    "        noise_x_int = tf.cast(noise_x_T, self.hz.dtype)\n",
    "        noise_z_int = tf.cast(noise_z_T, self.hx.dtype)\n",
    "        syndrome_x = int_mod_2(tf.matmul(self.hx, noise_z_int))\n",
    "        syndrome_z = int_mod_2(tf.matmul(self.hz, noise_x_int))\n",
    "\n",
    "        p0 = self.p0 \n",
    "        llr_ch_x = tf.fill(tf.shape(noise_x), tf.math.log(3.*(1.-p0)/p0))\n",
    "        llr = tf.tile(tf.expand_dims(llr_ch_x, axis=1), multiples=tf.constant([1, 3, 1], tf.int32))\n",
    "        # shape of llr: [bs, 3, self.n]\n",
    "        gt_x = int_mod_2(tf.matmul(self.hz, noise_x_int)) # [cn, bs]\n",
    "        gt_z = int_mod_2(tf.matmul(self.hx, noise_z_int))\n",
    "        \n",
    "        gt = tf.concat([gt_x, gt_z], axis=0) # [cn_x+cn_z, bs]\n",
    "        gt = tf.transpose(gt, (1,0))         # [bs, cn_x+cn_z]        \n",
    "       \n",
    "        # two-stage decoding, with GNN feedback in the middle\n",
    "        llrx, llry, llrz, x_hat_stage_one, z_hat_stage_one, logit_hx_perp, logit_hz_perp = self.decoder1((llr, syndrome_x, syndrome_z))\n",
    "\n",
    "        sx = int_mod_2(tf.matmul(self.hz, tf.transpose(tf.cast(x_hat_stage_one, self.hz.dtype), (1,0)))) # [cn, bs]\n",
    "        sz = int_mod_2(tf.matmul(self.hx, tf.transpose(tf.cast(z_hat_stage_one, self.hx.dtype), (1,0))))\n",
    "        \n",
    "        # find where flagged errors happened during first stage\n",
    "        s_hat = tf.transpose(tf.concat([sx, sz], axis=0), (1,0)) # [bs, cn_x+cn_z]\n",
    "        errors = tf.reduce_any(tf.not_equal(gt, s_hat), axis=-1)\n",
    "                      \n",
    "        h_vn = tf.stack([llrx, llry, llrz], axis=-1) # [bs, n, 3] GNN variable node values\n",
    "        \n",
    "        new_llr = self.feedback((h_vn, logit_hz_perp, logit_hx_perp, syndrome_x, syndrome_z))\n",
    "           \n",
    "        x_hat_stage_two, z_hat_stage_two = self.decoder2((tf.transpose(new_llr, (0,2,1)), syndrome_x, syndrome_z))\n",
    "\n",
    "        # update the second-stage results for where flagged errors happened\n",
    "        x_hat = tf.tensor_scatter_nd_update(x_hat_stage_one, tf.where(errors), x_hat_stage_two[errors])\n",
    "        z_hat = tf.tensor_scatter_nd_update(z_hat_stage_one, tf.where(errors), z_hat_stage_two[errors])         \n",
    "            \n",
    "        x_hat = tf.transpose(tf.cast(x_hat, tf.bool), (1,0)) # [self.n, bs]\n",
    "        z_hat = tf.transpose(tf.cast(z_hat, tf.bool), (1,0))\n",
    "\n",
    "        x_diff = tf.cast(tf.math.logical_xor(noise_x_T, x_hat), self.hx.dtype)\n",
    "        z_diff = tf.cast(tf.math.logical_xor(noise_z_T, z_hat), self.hz.dtype)\n",
    "\n",
    "        sx = int_mod_2(tf.matmul(self.hz, x_diff))\n",
    "        sz = int_mod_2(tf.matmul(self.hx, z_diff))\n",
    "        s_hat = tf.concat([sx, sz], axis=0)\n",
    "        s_hat = tf.transpose(s_hat, (1,0))\n",
    "        err = tf.reduce_any(tf.not_equal(tf.zeros_like(s_hat), s_hat), axis=-1)\n",
    "        return noise_x[err], noise_z[err]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93b0b4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def make_dataset(suffix=\"\", wt_from=0, wt_to=40, level=\"easy\"):\n",
    "    directory = '../sionna/fec/ldpc/datasets'\n",
    "    files = Path(directory).glob('*')\n",
    "    dataset_x = []\n",
    "    dataset_z = []\n",
    "    for file in files:\n",
    "        if not file.name.startswith(suffix):\n",
    "            continue\n",
    "        if not file.name.endswith('_x.npy'):\n",
    "            continue\n",
    "        wt = int(file.name.split('_')[-2][2:])\n",
    "        if wt_from <= wt and wt <= wt_to:\n",
    "            dataset_x.append(np.load(file))\n",
    "            file_z = file.name.replace('x', 'z')\n",
    "            dataset_z.append(np.load(directory+'/'+file_z))\n",
    "    dataset_x = np.vstack(dataset_x)\n",
    "    dataset_z = np.vstack(dataset_z)\n",
    "    print(\"dataset x shape\", dataset_x.shape)\n",
    "    dir_x = Path(directory+f'/{suffix}_wt_{wt_from}_{wt_to}_x_{level}.npy')\n",
    "    dir_z = Path(directory+f'/{suffix}_wt_{wt_from}_{wt_to}_z_{level}.npy')\n",
    "    \n",
    "    if Path(dir_x).exists():\n",
    "        print(f\"{dir_x} exists, adding new data to it\")\n",
    "        dataset_x = np.vstack([dataset_x, np.load(dir_x)])\n",
    "        \n",
    "    print(f\"saving dataset x of shape {dataset_x.shape} to {dir_x}\")\n",
    "    np.save(dir_x, dataset_x)\n",
    "    \n",
    "    if Path(dir_z).exists():\n",
    "        print(f\"{dir_z} exists, adding new data to it\")\n",
    "        dataset_z = np.vstack([dataset_z, np.load(dir_z)])\n",
    "        \n",
    "    print(f\"saving dataset z of shape {dataset_z.shape} to {dir_z}\")\n",
    "    np.save(dir_z, dataset_z)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09250ce",
   "metadata": {},
   "source": [
    "## Making the easy dataset\n",
    "Store error strings that a 64-iteration BP failed to decode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c445135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GHP_n882_k24 = create_QC_GHP_codes(63, create_cyclic_permuting_matrix(7, [27,54,0]), [0,1,6]) # 18 <= d <= 24\n",
    "# code = GHP_n882_k24\n",
    "GHP_n1270_k28 = create_QC_GHP_codes(127, np.array([[0,-1,51,52,-1],[-1,0,-1,111,20],[0,-1,98,-1,122],[0,80,-1,119,-1],[-1,0,5,-1,106]]), [0,1,7], name=\"GHP_n1270_k28\") # 16 <= d <= 46\n",
    "code = GHP_n1270_k28\n",
    "\n",
    "num_iter = 64\n",
    "decoder = QLDPCBPDecoder(code=code, num_iter=num_iter, normalization_factor=1.0, cn_type=\"boxplus-phi\")\n",
    "model = BP4_Error_Model(code, decoder, num_iter=tf.constant(num_iter), trainable=False, wt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957400fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell multiple times\n",
    "batch_size = tf.constant(50000)\n",
    "training_pipeline = zip(range(10, 61), [50]*51) # 1270\n",
    "# training_pipeline = zip(range(4, 41), [50]*37) # 882\n",
    "\n",
    "for wt, train_iter in training_pipeline:\n",
    "    print(f\"weight {wt}, find BP failed-to-decode samples for {train_iter} iterations.\")\n",
    "    wt = tf.constant(wt)\n",
    "    sample_x_list = []\n",
    "    sample_z_list = []\n",
    "    for _ in range(0, train_iter):\n",
    "        noise_x, noise_z = model(batch_size, wt)\n",
    "        sample_x_list.append(noise_x)\n",
    "        sample_z_list.append(noise_z)\n",
    "        \n",
    "    np.save(f\"../sionna/fec/ldpc/datasets/n1270_k28_wt{wt}_x.npy\", np.vstack(sample_x_list))\n",
    "    np.save(f\"../sionna/fec/ldpc/datasets/n1270_k28_wt{wt}_z.npy\", np.vstack(sample_z_list))   \n",
    "    \n",
    "#     np.save(f\"../sionna/fec/ldpc/datasets/n882_k24_wt{wt}_x.npy\", np.vstack(sample_x_list))\n",
    "#     np.save(f\"../sionna/fec/ldpc/datasets/n882_k24_wt{wt}_z.npy\", np.vstack(sample_z_list))   \n",
    "\n",
    "make_dataset(suffix=\"n1270_k28\", wt_from=10, wt_to=60, level=\"easy\")\n",
    "# make_dataset(suffix=\"n882_k24\", wt_from=4, wt_to=40, level=\"easy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78756fb3",
   "metadata": {},
   "source": [
    "### Go to Feedback_GNN.ipynb \n",
    "- Replace the dataset there by the easy dataset you generated, e.g. `../sionna/fec/ldpc/datasets/n1270_k28_wt_10_60_x_easy.npy`.\n",
    "- Change num_iter1 from 64 to 16. Leave num_iter2 as 16. I.e., the feedback GNN is sandwiched between two 16-iteration BP blocks.\n",
    "- Train a coarse feedback GNN model and save it as e.g. `../sionna/fec/ldpc/weights/feedback_GNN_n1270_k28_wt_10_60_iter_16_16.npy`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab4941f",
   "metadata": {},
   "source": [
    "## Making the hard-to-decode dataset \n",
    "Store error strings that a feedback GNN sandwiched between two 64-iteration BP blocks failed to decode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478f8a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "GHP_n1270_k28 = create_QC_GHP_codes(127, np.array([[0,-1,51,52,-1],[-1,0,-1,111,20],[0,-1,98,-1,122],[0,80,-1,119,-1],[-1,0,5,-1,106]]), [0,1,7], name=\"GHP_n1270_k28\") # 16 <= d <= 46\n",
    "code = GHP_n1270_k28\n",
    "\n",
    "# GHP_n882_k24 = create_QC_GHP_codes(63, create_cyclic_permuting_matrix(7, [27,54,0]), [0,1,6]) # 18 <= d <= 24\n",
    "# code = GHP_n882_k24\n",
    "\n",
    "############## load model ########################\n",
    "feedback_GNN = Feedback_GNN(code=code, \n",
    "                 num_msg_dims=tf.constant(20),\n",
    "                 num_hidden_units=tf.constant(40),\n",
    "                 num_mlp_layers=2,\n",
    "                 reduce_op=\"mean\",      ######### change here\n",
    "                 activation=\"tanh\",\n",
    "                 use_bias=True)\n",
    "\n",
    "bs = tf.constant(100)\n",
    "n = tf.constant(code.N)\n",
    "cn_z = tf.constant(code.hz.shape[0])\n",
    "cn_x = tf.constant(code.hx.shape[0])\n",
    "feedback_GNN((tf.zeros((bs, n, 3)), tf.zeros((cn_x, bs)), tf.zeros((cn_z, bs)), \n",
    "                  tf.zeros((cn_x, bs)), tf.zeros((cn_z, bs))))\n",
    "\n",
    "# load the trained coarse GNN\n",
    "load_weights(feedback_GNN, f\"../sionna/fec/ldpc/weights/feedback_GNN_n1270_k28_wt_10_60_iter_16_16.npy\")\n",
    "# load_weights(feedback_GNN, f\"../sionna/fec/ldpc/weights/feedback_GNN_n882_k24_wt_4_40_iter_16_16.npy\")\n",
    "##################################################\n",
    "\n",
    "num_iter1 = tf.constant(64)\n",
    "num_iter2 = tf.constant(64)\n",
    "factor1 = tf.constant(1.0)\n",
    "factor2 = tf.constant(1.0)\n",
    "decoder1 = QLDPCBPDecoder(code=code, num_iter=num_iter1, normalization_factor=factor1, cn_type=\"boxplus-phi\", trainable=False, stage_one=True)\n",
    "decoder2 = QLDPCBPDecoder(code=code, num_iter=num_iter2, normalization_factor=factor2, cn_type=\"boxplus-phi\", trainable=False)\n",
    "model = Feedback_GNN_Error_Model(code, decoder1, feedback_GNN, decoder2, wt=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6407ab81",
   "metadata": {},
   "source": [
    "## 1270 Dataset contains \n",
    "- easy: 867278 samples of weight 10-60, 856 samples of weight 61-80.\n",
    "- hard: 5779 samples of weight 10-60, 3000 samples of weight 61-80. Repeated for 50 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a14af38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell until you gathered ~10K samples\n",
    "batch_size = tf.constant(5000)\n",
    "training_pipeline = zip(range(10, 81)[::-1], [200]*71)\n",
    "\n",
    "for wt, train_iter in training_pipeline:\n",
    "    print(f\"weight {wt}, find two-stage difficult samples for {train_iter} iterations.\")\n",
    "    wt = tf.constant(wt)\n",
    "    sample_x_list = []\n",
    "    sample_z_list = []\n",
    "    for _ in range(0, train_iter):\n",
    "        noise_x, noise_z = model(batch_size, wt)\n",
    "        sample_x_list.append(noise_x)\n",
    "        sample_z_list.append(noise_z)\n",
    "    np.save(f\"../sionna/fec/ldpc/datasets/n1270_k28_wt{wt}_x.npy\", np.vstack(sample_x_list))\n",
    "    np.save(f\"../sionna/fec/ldpc/datasets/n1270_k28_wt{wt}_z.npy\", np.vstack(sample_z_list))  \n",
    "    \n",
    "make_dataset(\"n1270_k28\", 10, 80, 'hard')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054a9311",
   "metadata": {},
   "source": [
    "Looking at the distribution of the dataset, we notice that there are too many error strings of weight 61-80. Therefore, we split the dataset into two, weight 10-60 and weight 61-80 and only select 3000 samples from the latter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffef2e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13847, 1270)\n",
      "(13847, 1270)\n",
      "(13847,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.load(\"../sionna/fec/ldpc/datasets/n1270_k28_wt_10_80_x_hard.npy\")\n",
    "z = np.load(\"../sionna/fec/ldpc/datasets/n1270_k28_wt_10_80_z_hard.npy\")\n",
    "print(x.shape)\n",
    "print(z.shape)\n",
    "a = np.logical_or(x, z)\n",
    "wt = np.sum(a, axis=1)\n",
    "print(wt.shape)\n",
    "plt.hist(wt)\n",
    "\n",
    "min_wt = 10\n",
    "max_wt = 60\n",
    "mask = np.logical_and(wt<=max_wt, wt>=min_wt)\n",
    "np.save(f\"../sionna/fec/ldpc/datasets/n1270_k28_wt_{min_wt}_{max_wt}_x_hard.npy\", x[mask])\n",
    "np.save(f\"../sionna/fec/ldpc/datasets/n1270_k28_wt_{min_wt}_{max_wt}_z_hard.npy\", z[mask])\n",
    "\n",
    "min_wt = 61\n",
    "max_wt = 80\n",
    "mask = np.logical_and(wt<=max_wt, wt>=min_wt)\n",
    "np.save(f\"../sionna/fec/ldpc/datasets/n1270_k28_wt_{min_wt}_{max_wt}_x_hard.npy\", x[mask])\n",
    "np.save(f\"../sionna/fec/ldpc/datasets/n1270_k28_wt_{min_wt}_{max_wt}_z_hard.npy\", z[mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5dae5369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5779, 1270)\n",
      "(3000, 1270)\n",
      "(856, 1270)\n",
      "(867278, 1270)\n",
      "(1307084, 1270)\n"
     ]
    }
   ],
   "source": [
    "dx_10_60_hard = np.load(f\"../sionna/fec/ldpc/datasets/n1270_k28_wt_10_60_x_hard.npy\")\n",
    "dz_10_60_hard = np.load(f\"../sionna/fec/ldpc/datasets/n1270_k28_wt_10_60_z_hard.npy\")\n",
    "\n",
    "dx_61_80_hard = np.load(f\"../sionna/fec/ldpc/datasets/n1270_k28_wt_61_80_x_hard.npy\")\n",
    "dz_61_80_hard = np.load(f\"../sionna/fec/ldpc/datasets/n1270_k28_wt_61_80_z_hard.npy\")\n",
    "\n",
    "mask = np.random.choice(dx_61_80_hard.shape[0], 3000, replace=False)\n",
    "\n",
    "dx_61_80_hard = dx_61_80_hard[mask,:]\n",
    "dz_61_80_hard = dz_61_80_hard[mask,:]\n",
    "\n",
    "dx_10_60_easy = np.load(f\"../sionna/fec/ldpc/datasets/n1270_k28_wt_10_60_x_easy.npy\")\n",
    "dz_10_60_easy = np.load(f\"../sionna/fec/ldpc/datasets/n1270_k28_wt_10_60_z_easy.npy\")\n",
    "\n",
    "# (optional) generate some easy samples of weight 61-80\n",
    "dx_61_80_easy = np.load(f\"../sionna/fec/ldpc/datasets/n1270_k28_wt_61_80_x_easy.npy\")\n",
    "dz_61_80_easy = np.load(f\"../sionna/fec/ldpc/datasets/n1270_k28_wt_61_80_z_easy.npy\")\n",
    "\n",
    "print(dx_10_60_hard.shape)\n",
    "print(dx_61_80_hard.shape)\n",
    "print(dx_61_80_easy.shape)\n",
    "print(dx_10_60_easy.shape)\n",
    "\n",
    "dx_all = np.vstack([dx_10_60_easy]+[dx_61_80_easy]+[dx_10_60_hard]*50+[dx_61_80_hard]*50)\n",
    "dz_all = np.vstack([dz_10_60_easy]+[dz_61_80_easy]+[dz_10_60_hard]*50+[dz_61_80_hard]*50)\n",
    "print(dx_all.shape)\n",
    "\n",
    "np.save(f\"../sionna/fec/ldpc/datasets/n1270_k28_wt_10_80_x_all.npy\", dx_all)\n",
    "np.save(f\"../sionna/fec/ldpc/datasets/n1270_k28_wt_10_80_z_all.npy\", dz_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467b91a4",
   "metadata": {},
   "source": [
    "## 882 Dataset contains \n",
    "- easy: 439916 samples of weight 4-40, 300000 samples of weight 41-60.\n",
    "- hard: 6912 samples of weight 4-40, 4032 samples of weight 41-60. Repeated for 50 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e7f2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This time, split the hard dataset generation into weight 4-40 and weight 41-60.\n",
    "# Run this cell multiple times\n",
    "batch_size = tf.constant(5000)\n",
    "training_pipeline = zip(range(41, 61)[::-1], [200]*20)\n",
    "# training_pipeline = zip(range(4, 40)[::-1], [200]*36)\n",
    "\n",
    "for wt, train_iter in training_pipeline:\n",
    "    print(f\"weight {wt}, find two-stage difficult samples for {train_iter} iterations.\")\n",
    "    wt = tf.constant(wt)\n",
    "    sample_x_list = []\n",
    "    sample_z_list = []\n",
    "    for _ in range(0, train_iter):\n",
    "        noise_x, noise_z = model(batch_size, wt)\n",
    "        sample_x_list.append(noise_x)\n",
    "        sample_z_list.append(noise_z)\n",
    "    np.save(f\"../sionna/fec/ldpc/datasets/n882_k24_wt{wt}_x.npy\", np.vstack(sample_x_list))\n",
    "    np.save(f\"../sionna/fec/ldpc/datasets/n882_k24_wt{wt}_z.npy\", np.vstack(sample_z_list))  \n",
    "    \n",
    "make_dataset(\"n882_k24\", 41, 60, 'hard')\n",
    "# make_dataset(\"n882_k24\", 4, 40, 'hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4765c6af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6912, 882)\n",
      "(4032, 882)\n",
      "(439916, 882)\n",
      "(1020472, 882)\n",
      "(1287116, 882)\n"
     ]
    }
   ],
   "source": [
    "dx_4_40_hard = np.load(f\"../sionna/fec/ldpc/datasets/n882_k24_wt_4_40_x_hard.npy\")\n",
    "dz_4_40_hard = np.load(f\"../sionna/fec/ldpc/datasets/n882_k24_wt_4_40_z_hard.npy\")\n",
    "\n",
    "dx_41_60_hard = np.load(f\"../sionna/fec/ldpc/datasets/n882_k24_wt_41_60_x_hard.npy\")\n",
    "dz_41_60_hard = np.load(f\"../sionna/fec/ldpc/datasets/n882_k24_wt_41_60_x_hard.npy\")\n",
    "\n",
    "dx_4_40_easy = np.load(f\"../sionna/fec/ldpc/datasets/n882_k24_wt_4_40_x_easy.npy\")\n",
    "dz_4_40_easy = np.load(f\"../sionna/fec/ldpc/datasets/n882_k24_wt_4_40_z_easy.npy\")\n",
    "\n",
    "dx_41_60_easy = np.load(f\"../sionna/fec/ldpc/datasets/n882_k24_wt_41_60_x_easy.npy\")\n",
    "dz_41_60_easy = np.load(f\"../sionna/fec/ldpc/datasets/n882_k24_wt_41_60_z_easy.npy\")\n",
    "\n",
    "\n",
    "print(dx_4_40_hard.shape)\n",
    "print(dx_41_60_hard.shape)\n",
    "print(dx_4_40_easy.shape)\n",
    "print(dx_41_60_easy.shape)\n",
    "\n",
    "mask_easy = np.random.choice(dx_41_60_easy.shape[0], 300000, replace=False)\n",
    "\n",
    "dx_all = np.vstack([dx_4_40_easy]+[dx_41_60_easy[mask_easy,:]]+[dx_4_40_hard]*50 + [dx_41_60_hard]*50)\n",
    "dz_all = np.vstack([dz_4_40_easy]+[dz_41_60_easy[mask_easy,:]]+[dz_4_40_hard]*50 + [dz_41_60_hard]*50)\n",
    "print(dx_all.shape)\n",
    "\n",
    "np.save(f\"../sionna/fec/ldpc/datasets/n882_k24_wt_4_60_x_all.npy\", dx_all)\n",
    "np.save(f\"../sionna/fec/ldpc/datasets/n882_k24_wt_4_60_z_all.npy\", dz_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22118cfe",
   "metadata": {},
   "source": [
    "## Go back to Feedback_GNN.ipynb to train the final model using the mixed dataset.\n",
    "- Set num_iter1 to 64 and num_iter2 to 16."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
