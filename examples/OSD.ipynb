{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "027909e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available : 1\n",
      "Only GPU number 0 used.\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # INFO, WARNING messages are not printed\n",
    "import tensorflow as tf\n",
    "import time # for throughput measurements\n",
    "\n",
    "# Configure the notebook to use only a single GPU and allocate only as much memory as needed\n",
    "# For more details, see https://www.tensorflow.org/guide/gpu\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print('Number of GPUs available :', len(gpus))\n",
    "if gpus:\n",
    "    gpu_num = 0 # Number of the GPU to be used\n",
    "    try:\n",
    "        #tf.config.set_visible_devices([], 'GPU')\n",
    "        tf.config.set_visible_devices(gpus[gpu_num], 'GPU')\n",
    "        print('Only GPU number', gpu_num, 'used.')\n",
    "        tf.config.experimental.set_memory_growth(gpus[gpu_num], True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# uninstall sionna first\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(str(Path('..')))\n",
    "\n",
    "from sionna.fec.ldpc import *\n",
    "from sionna.utils import BinarySource \n",
    "from sionna.utils.metrics import count_block_errors\n",
    "from sionna.channel import Pauli, BinarySymmetricChannel\n",
    "from sionna.utils.plotting import PlotBER\n",
    "\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from sionna.utils.metrics import compute_bler\n",
    "from sionna.fec.utils import int_mod_2, row_echelon\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cca3d51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 5 2 0 4 3]\n",
      "[3 0 2 5 4 1]\n",
      "[3 0 2 5 4 1]\n"
     ]
    }
   ],
   "source": [
    "# a = tf.constant([[0.7,0.2,0.3],[0.4,0.7,0.1]])\n",
    "a = tf.constant([0.7,0.2,0.3,1.9,0.8,0.2])\n",
    "sort_order = tf.argsort(a)\n",
    "inv_sort = tf.math.invert_permutation(sort_order)\n",
    "inv_sort_2 = tf.argsort(sort_order)\n",
    "tf.print(sort_order)\n",
    "tf.print(inv_sort)\n",
    "tf.print(inv_sort_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ab7ebcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([3 2 3], shape=(3,), dtype=int32)\n",
      "tf.Tensor([3 2], shape=(2,), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2, 2), dtype=int32, numpy=\n",
       "array([[[  1,  10],\n",
       "        [  2,  20]],\n",
       "\n",
       "       [[ 30, 300],\n",
       "        [ 40, 400]],\n",
       "\n",
       "       [[500,   5],\n",
       "        [600,   6]]], dtype=int32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tf.constant([[[1, 10, 100], [2, 20, 200]],\n",
    "                 [[3, 30, 300], [4, 40, 400]],\n",
    "                 [[5, 50, 500], [6, 60, 600]]])\n",
    "print(tf.shape(t))\n",
    "indices = tf.constant([[0,1], [1,2], [2,0]])\n",
    "print(tf.shape(indices))\n",
    "tf.gather(t, indices, batch_dims=1, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "03737636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([2 1], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "indices = [[0],[1]]\n",
    "print(tf.shape(indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5972a9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0 0 0]\n",
      " [1 1 1]], shape=(2, 3), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[[0 1]\n",
      "  [0 3]\n",
      "  [0 2]]\n",
      "\n",
      " [[1 3]\n",
      "  [1 2]\n",
      "  [1 1]]], shape=(2, 3, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "idx_pivot = [[1,3,2],[3,2,1]]\n",
    "ii, _ = tf.meshgrid(tf.range(2), tf.range(3), indexing='ij')\n",
    "print(ii)\n",
    "idx_updates = tf.stack([ii, idx_pivot], axis=-1)\n",
    "print(idx_updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "14570032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 8)\n",
      "(2, 4, 2)\n",
      "(2, 4)\n",
      "tf.Tensor(\n",
      "[[ 0  9  0 11 12  0  0 10]\n",
      " [ 0  0  2  4  0  5  3  0]], shape=(2, 8), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "tensor = tf.constant([[0, 0, 0, 0, 0, 0, 0, 0], [0,0,0,0,0,0,0,0]])    # tf.rank(tensor) == 1\n",
    "# indices = [[1], [7], [3], [4]]       # num_updates == 4, index_depth == 1\n",
    "indices = tf.constant([[[0,1],[0,7],[0,3],[0,4]],[[1,2],[1,6],[1,3],[1,5]]])\n",
    "# updates = [9, 10, 11, 12] \n",
    "updates = tf.constant([[9,10,11,12],[2,3,4,5]])\n",
    "print(tensor.shape)\n",
    "print(indices.shape)\n",
    "print(updates.shape)\n",
    "print(tf.tensor_scatter_nd_update(tensor, indices, updates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1584fecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BP4_Error_Model(tf.keras.Model):\n",
    "# For storing error strings that the BP decoder failed to decode\n",
    "    def __init__(self, code, decoder, num_iter=32, trainable=False, loss_type=\"boxplus-phi\", wt=False):\n",
    "\n",
    "        super().__init__()\n",
    "        \n",
    "        self.k = code.K      \n",
    "        self.n = code.N\n",
    "        self.hx = code.hx\n",
    "        self.hz = code.hz\n",
    "        self.lx = code.lx\n",
    "        self.lz = code.lz\n",
    "        self.hx_perp = code.hx_perp # contains Im(hz.T)\n",
    "        self.hz_perp = code.hz_perp # contains Im(hx.T)\n",
    "        self.code_name = code.name\n",
    "        self.num_checks = code.hx.shape[0] + code.hz.shape[0]\n",
    "        \n",
    "        self.source = BinarySource()\n",
    "        self.channel = Pauli(wt=wt)\n",
    "        self.decoder = decoder\n",
    "\n",
    "        self.num_iter = num_iter\n",
    "        self.trainable = trainable\n",
    "        self.bce = BinaryCrossentropy(from_logits=True)\n",
    "        self.loss_type = loss_type\n",
    "        self.wt = wt\n",
    "           \n",
    "    @tf.function(jit_compile=True, reduce_retracing=True) # XLA mode\n",
    "    def call(self, batch_size, ebno_db):\n",
    "\n",
    "        p = ebno_db\n",
    "\n",
    "        # depolarizing noise\n",
    "        px, py, pz = 2*p/3, p/3, 2*p/3\n",
    "        c_dummy = tf.zeros([batch_size, self.n])\n",
    "        if self.wt: # ebno_db is an integer indicating the weight of the error\n",
    "            noise_x, noise_z = self.channel([c_dummy, None, p])\n",
    "        else:\n",
    "            noise_x, noise_z = self.channel([c_dummy, None, px, py, pz])  # [bs, self.n]\n",
    "        noise_x_T, noise_z_T = tf.transpose(noise_x, (1,0)), tf.transpose(noise_z, (1,0))\n",
    "        noise_x_int = tf.cast(noise_x_T, self.hz.dtype)\n",
    "        noise_z_int = tf.cast(noise_z_T, self.hx.dtype)\n",
    "        syndrome_x = int_mod_2(tf.matmul(self.hx, noise_z_int))\n",
    "        syndrome_z = int_mod_2(tf.matmul(self.hz, noise_x_int))\n",
    "\n",
    "        llr_ch_x = tf.fill(tf.shape(noise_x), tf.math.log(3.*(1.-p)/p))\n",
    "        llr = tf.tile(tf.expand_dims(llr_ch_x, axis=1), multiples=tf.constant([1, 3, 1], tf.int32))\n",
    "        # shape of llr: [bs, 3, self.n]\n",
    "        \n",
    "        x_hat, z_hat = self.decoder((llr, syndrome_x, syndrome_z))\n",
    "        \n",
    "        x_hat = tf.transpose(tf.cast(x_hat, tf.bool), (1,0)) # [self.n, bs]\n",
    "        z_hat = tf.transpose(tf.cast(z_hat, tf.bool), (1,0))\n",
    "\n",
    "        x_diff = tf.cast(tf.math.logical_xor(noise_x_T, x_hat), self.hx_perp.dtype)\n",
    "        z_diff = tf.cast(tf.math.logical_xor(noise_z_T, z_hat), self.hz_perp.dtype)\n",
    "\n",
    "        sx = int_mod_2(tf.matmul(self.hz, x_diff))\n",
    "        sz = int_mod_2(tf.matmul(self.hx, z_diff))\n",
    "        s_hat = tf.concat([sx, sz], axis=0)\n",
    "        s_hat = tf.transpose(s_hat, (1,0))\n",
    "        err = tf.reduce_any(tf.not_equal(tf.zeros_like(s_hat), s_hat), axis=-1)\n",
    "        return noise_x, noise_z, x_hat, z_hat, err\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "431f4eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OSD_Model(tf.keras.Model):\n",
    "# For storing error strings that the BP decoder failed to decode\n",
    "    def __init__(self, code, decoder, num_iter=32, trainable=False, loss_type=\"boxplus-phi\", wt=False):\n",
    "\n",
    "        super().__init__()\n",
    "        \n",
    "        self.k = code.K      \n",
    "        self.n = code.N\n",
    "        self.hx = code.hx\n",
    "        self.hz = code.hz\n",
    "        self.rank_hx, self.pivot_hx, self.hx_basis = code.rank_hx, code.pivot_hx, code.hx_basis\n",
    "        self.rank_hz, self.pivot_hz, self.hz_basis = code.rank_hz, code.pivot_hz, code.hz_basis\n",
    "        self.lx = code.lx\n",
    "        self.lz = code.lz\n",
    "        self.hx_perp = code.hx_perp # contains Im(hz.T)\n",
    "        self.hz_perp = code.hz_perp # contains Im(hx.T)\n",
    "        self.code_name = code.name\n",
    "        self.num_checks = code.hx.shape[0] + code.hz.shape[0]\n",
    "        \n",
    "        self.source = BinarySource()\n",
    "        self.channel = Pauli(wt=wt)\n",
    "        self.decoder = decoder\n",
    "\n",
    "        self.num_iter = num_iter\n",
    "        self.trainable = trainable\n",
    "        self.bce = BinaryCrossentropy(from_logits=True)\n",
    "        self.loss_type = loss_type\n",
    "        self.wt = wt\n",
    "        \n",
    "        \n",
    "    @tf.function(jit_compile=True, reduce_retracing=True)\n",
    "    def find_mrb(self, pcm, bs):\n",
    "        # the parity check matrix must be full-rank\n",
    "        # find most reliable basis for the parity check matrix of size [bs, rank, n]\n",
    "        # column-wise gaussian elimination\n",
    "        # find pivot for each row\n",
    "\n",
    "        _, rank, _ = pcm.shape\n",
    "        s = pcm.shape\n",
    "\n",
    "        idx_pivot = tf.TensorArray(tf.int32, rank, dynamic_size=False)\n",
    "        \n",
    "        for row in tf.range(rank):\n",
    "            pcm = tf.ensure_shape(pcm, s)\n",
    "            \n",
    "            # find pivot and store it in TensorArray\n",
    "            idx_p = tf.argmax(pcm[:, row, :], axis=-1, output_type=tf.int32) # size [bs]\n",
    "            idx_pivot = idx_pivot.write(row, idx_p)\n",
    "            \n",
    "            # gather the idx_pivot'th column from pcm\n",
    "            c = tf.gather(pcm, idx_p, batch_dims=1, axis=-1) # [bs, rank]\n",
    "            \n",
    "            # do not eliminate current row, i.e., c[:,row]=0\n",
    "            all_zero = tf.zeros((bs, 1), dtype=tf.int32)\n",
    "            c = tf.concat([c[:,:row], all_zero, c[:,row+1:]], axis=1) # or use tensor_scatter_nd_update?\n",
    "            c = tf.tile(tf.expand_dims(c, axis=-1), (1, 1, self.n+1)) # [bs, rank, n+1]\n",
    "            \n",
    "            # use current row to eliminate all other rows\n",
    "            current_row = tf.expand_dims(pcm[:,row,:], axis=1) # [bs, 1 ,n]                        \n",
    "            pcm = int_mod_2(pcm + c * current_row)\n",
    "           \n",
    "        idx_pivot = tf.transpose(idx_pivot.stack()) # [bs, rank]\n",
    "        sol = tf.cast(pcm[:,:,-1], tf.bool) # last column, [bs, rank]\n",
    "        return idx_pivot, sol\n",
    "   \n",
    "    @tf.function(jit_compile=True, reduce_retracing=True)    \n",
    "    def osd0(self, llr, pcm, s, bs):\n",
    "        # use llrz together with code.hx and syndrome_x, return noise_z_hat\n",
    "\n",
    "        sort_order = tf.argsort(llr) # [bs, n]\n",
    "        pcm = tf.cast(pcm, tf.int32)\n",
    "\n",
    "        permuted_pcm = tf.gather(pcm, sort_order, batch_dims=1, axis=-1)\n",
    "\n",
    "        inv_sort = tf.argsort(sort_order) # is it correct ???\n",
    "        \n",
    "        syndrome = tf.cast(tf.expand_dims(tf.transpose(s, (1,0)), -1), permuted_pcm.dtype) # [bs, rank, 1]\n",
    "        pcm_syndrome = tf.concat((permuted_pcm, syndrome), axis=-1) # [bs, rank, n+1]\n",
    "\n",
    "        idx_pivot, sol = self.find_mrb(pcm_syndrome, bs)\n",
    "\n",
    "\n",
    "        # [bs, rank, rank] * [bs, rank, 1] = [bs, rank, 1]\n",
    "        _, rank = sol.shape\n",
    "        ii, _ = tf.meshgrid(tf.range(bs), tf.range(rank), indexing='ij')\n",
    "        # for sample i in the batch, update using idx_pivot[i]\n",
    "        \n",
    "        ii = tf.cast(ii, tf.int32)\n",
    "        idx_pivot = tf.cast(idx_pivot, tf.int32)\n",
    "        idx_updates = tf.stack([ii, idx_pivot], axis=-1) # [bs, rank, 2]\n",
    "\n",
    "        e_hat = tf.tensor_scatter_nd_update(tf.zeros_like(llr, dtype=tf.bool), idx_updates, sol)\n",
    "        e_hat = tf.gather(e_hat, inv_sort, batch_dims=1, axis=-1)\n",
    "\n",
    "        return e_hat        \n",
    "\n",
    "    \n",
    "    @tf.function(jit_compile=True, reduce_retracing=True) # XLA mode\n",
    "    def call(self, noise_x, noise_z, p, batch_size):    \n",
    "#         batch_size = noise_x.shape[0]\n",
    "        noise_x_T, noise_z_T = tf.transpose(noise_x, (1,0)), tf.transpose(noise_z, (1,0))\n",
    "        noise_x_int = tf.cast(noise_x_T, self.hz.dtype)\n",
    "        noise_z_int = tf.cast(noise_z_T, self.hx.dtype)\n",
    "        syndrome_x = int_mod_2(tf.matmul(self.hx, noise_z_int))\n",
    "        syndrome_z = int_mod_2(tf.matmul(self.hz, noise_x_int))\n",
    "\n",
    "        llr_ch_x = tf.fill(tf.shape(noise_x), tf.math.log(3.*(1.-p)/p))\n",
    "        llr = tf.tile(tf.expand_dims(llr_ch_x, axis=1), multiples=tf.constant([1, 3, 1], tf.int32))\n",
    "        # shape of llr: [bs, 3, self.n]\n",
    "        \n",
    "        llrx, llry, llrz, x_hat, z_hat, _, _ = self.decoder((llr, syndrome_x, syndrome_z))\n",
    "       \n",
    "        x_hat = tf.transpose(tf.cast(x_hat, tf.bool), (1,0)) # [self.n, bs]\n",
    "        z_hat = tf.transpose(tf.cast(z_hat, tf.bool), (1,0))\n",
    "\n",
    "        x_diff = tf.cast(tf.math.logical_xor(noise_x_T, x_hat), self.hx_perp.dtype)\n",
    "        z_diff = tf.cast(tf.math.logical_xor(noise_z_T, z_hat), self.hz_perp.dtype)\n",
    "\n",
    "        sx = int_mod_2(tf.matmul(self.hz, x_diff))\n",
    "        sz = int_mod_2(tf.matmul(self.hx, z_diff))\n",
    "        s_hat = tf.concat([sx, sz], axis=0)\n",
    "        s_hat = tf.transpose(s_hat, (1,0))\n",
    "        err = tf.reduce_any(tf.not_equal(tf.zeros_like(s_hat), s_hat), axis=-1)\n",
    "         \n",
    "        reduced_sx = tf.gather(syndrome_x, self.pivot_hx, axis=0) # [rank, new_bs]\n",
    "        reduced_sz = tf.gather(syndrome_z, self.pivot_hz, axis=0) # [rank, new_bs]\n",
    "        \n",
    "        num_hx = tf.math.softplus(-1.*llrx) # I or X, both commute with X-type check\n",
    "        denom_hx = tf.ragged.map_flat_values(lambda x, y: tf.math.reduce_logsumexp(-1.*tf.stack([x, y], axis=-1), axis=-1), llrz, llry)\n",
    "        new_llr_z = num_hx - denom_hx\n",
    "\n",
    "        num_hz = tf.math.softplus(-1.*llrz) # I or Z, both commute with Z-type check\n",
    "        denom_hz = tf.ragged.map_flat_values(lambda x, y: tf.math.reduce_logsumexp(-1.*tf.stack([x, y], axis=-1), axis=-1), llrx, llry)\n",
    "        new_llr_x = num_hz - denom_hz\n",
    "        \n",
    "\n",
    "        full_rank_hx = tf.broadcast_to(tf.expand_dims(self.hx_basis, axis=0),\n",
    "                             (batch_size, self.rank_hx, self.n))\n",
    "        full_rank_hz = tf.broadcast_to(tf.expand_dims(self.hz_basis, axis=0),\n",
    "                             (batch_size, self.rank_hz, self.n))\n",
    "\n",
    "        z_hat_osd = self.osd0(new_llr_z, full_rank_hx, reduced_sx, batch_size)\n",
    "        x_hat_osd = self.osd0(new_llr_x, full_rank_hz, reduced_sz, batch_size)\n",
    "        \n",
    "        return x_hat_osd, z_hat_osd\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1925392",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BP4_OSD_Model(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, code, bp4_model, osd_model):\n",
    "\n",
    "        super().__init__()\n",
    "        self.bp4_model = bp4_model\n",
    "        self.osd_mode = osd_model\n",
    "\n",
    "        self.hx_perp = code.hx_perp # contains Im(hz.T)\n",
    "        self.hz_perp = code.hz_perp # contains Im(hx.T)\n",
    "        \n",
    "    def call(self, batch_size, ebno_db):\n",
    "        noise_x, noise_z, x_hat, z_hat, err = self.bp4_model(batch_size, ebno_db)\n",
    "        nx, nz = noise_x[err], noise_z[err]\n",
    "        new_bs = tf.reduce_sum(tf.cast(err, tf.int32))\n",
    "        x_hat_osd, z_hat_osd = osd_model(nx, nz, ebno_db, new_bs)\n",
    "        \n",
    "        new_x_hat = tf.tensor_scatter_nd_update(tf.transpose(x_hat, (1,0)), tf.where(err), x_hat_osd)\n",
    "        new_z_hat = tf.tensor_scatter_nd_update(tf.transpose(z_hat, (1,0)), tf.where(err), z_hat_osd)\n",
    "        \n",
    "        new_x_hat_T = tf.transpose(new_x_hat, (1,0))\n",
    "        new_z_hat_T = tf.transpose(new_z_hat, (1,0))\n",
    "        x_diff = tf.cast(tf.math.logical_xor(tf.transpose(noise_x, (1,0)), new_x_hat_T), self.hx_perp.dtype)\n",
    "        z_diff = tf.cast(tf.math.logical_xor(tf.transpose(noise_z, (1,0)), new_z_hat_T), self.hz_perp.dtype)\n",
    "  \n",
    "        lsx = int_mod_2(tf.matmul(self.hx_perp, x_diff))\n",
    "        lsz = int_mod_2(tf.matmul(self.hz_perp, z_diff))\n",
    "            \n",
    "        ls_hat = tf.concat([lsx, lsz], axis=0)      # for total logical error counts\n",
    "\n",
    "        ls_hat = tf.transpose(ls_hat, (1,0))         # bs should be the first dimension!!!\n",
    "\n",
    "        return tf.zeros_like(ls_hat), ls_hat     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d1554f3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start_time = time.perf_counter()\n",
    "\n",
    "GHP_n882_k24 = create_QC_GHP_codes(63, create_cyclic_permuting_matrix(7, [27,54,0]), [0,1,6]) # 18 <= d <= 24\n",
    "code = GHP_n882_k24\n",
    "# GHP_n1270_k28 = create_QC_GHP_codes(127, np.array([[0,-1,51,52,-1],[-1,0,-1,111,20],[0,-1,98,-1,122],[0,80,-1,119,-1],[-1,0,5,-1,106]]), [0,1,7], name=\"GHP_n1270_k28\") # 16 <= d <= 46\n",
    "# code = GHP_n1270_k28\n",
    "num_iter = tf.constant(100)\n",
    "factor=tf.constant(0.8)\n",
    "\n",
    "decoder_hard = QLDPCBPDecoder(code=code, num_iter=num_iter, normalization_factor=factor, cn_type=\"minsum\", trainable=False, stage_one=False)\n",
    "decoder_soft = QLDPCBPDecoder(code=code, num_iter=num_iter, normalization_factor=factor, cn_type=\"minsum\", trainable=False, stage_one=True)\n",
    "\n",
    "bp4_model = BP4_Error_Model(code, decoder_hard, num_iter=num_iter, trainable=False, wt=False)\n",
    "osd_model = OSD_Model(code, decoder_soft, num_iter=num_iter, trainable=False, wt=False)\n",
    "bp4_osd_model = BP4_OSD_Model(code, bp4_model, osd_model)\n",
    "batch_size = tf.constant(50000)\n",
    "p = tf.constant(0.09)\n",
    "\n",
    "# for i in range(10):\n",
    "#     start_time = time.perf_counter()\n",
    "#     bp4_osd_model(batch_size, p)\n",
    "#     end_time = time.perf_counter()\n",
    "#     print(\"Elapsed time: \", end_time-start_time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16c9abb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "      0.1 | 5.9308e-05 | 3.4667e-04 |       16120 |   271800000 |          104 |      300000 |        95.6 |reached target block errors\n",
      "     0.09 | 8.6908e-06 | 5.1795e-05 |       15354 |  1766700000 |          101 |     1950000 |       454.6 |reached target block errors\n",
      "     0.08 | 1.1202e-06 | 7.0922e-06 |       14310 | 12774600000 |          100 |    14100000 |      2440.1 |reached target block errors\n"
     ]
    }
   ],
   "source": [
    "p_range = np.arange(0.08,0.101,0.01)[::-1]\n",
    "\n",
    "ber_plot = PlotBER(\"Performance of the [[882,24]] code on BSC channel under binary decoding\")\n",
    "\n",
    "ber_plot.simulate(bp4_osd_model, \n",
    "                  ebno_dbs=p_range, # physical error rates to simulate\n",
    "                  legend=f\"{code.name}, factor={factor}, iter={num_iter}\", # legend string for plotting\n",
    "                  max_mc_iter=1000, # run 1000 Monte Carlo runs per physical error rate point\n",
    "                  num_target_block_errors=100, # continue with next physical error rate point after 1000 block errors\n",
    "                  batch_size=50000, # batch-size per Monte Carlo run\n",
    "                  soft_estimates=False, # the model returns hard-estimates\n",
    "                  early_stop=True, # stop simulation if no error has been detected at current physical error rate\n",
    "                  show_fig=False, # do not show the figure after all results are simulated\n",
    "                  add_bler=True, # we are interested in block error rate\n",
    "                  qldpc=False, # since there is no flagged error for bp-osd\n",
    "                  forward_keyboard_interrupt=True, # should be True in a loop\n",
    "                  graph_mode=None);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6355c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[119 882]\n",
      "[441 119]\n",
      "[[0 1 1 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 1]\n",
      " ...\n",
      " [0 1 0 ... 0 0 1]\n",
      " [0 1 0 ... 1 0 0]\n",
      " [0 0 0 ... 0 1 0]]\n",
      "[[0 0 0 ... 0 0 1]\n",
      " [1 1 1 ... 0 0 0]\n",
      " [1 0 1 ... 1 1 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 1]\n",
      " [0 1 0 ... 0 1 1]]\n",
      "llrx shape [119 882]\n",
      "[[43.3375244 43.3375244 -36.513031 ... -36.513031 43.3375244 43.3375244]\n",
      " [43.3375244 43.3375244 43.3375244 ... 43.3375244 43.3375244 43.3375244]\n",
      " [2.68565249 26.255352 -24.9922771 ... 22.6572895 22.4827442 23.6940384]\n",
      " ...\n",
      " [43.3375244 43.3375244 43.3375244 ... 43.3375244 43.3375244 43.3375244]\n",
      " [43.3375244 43.3375244 43.3375244 ... 43.3375244 43.3375244 43.3375244]\n",
      " [-2.61972761 23.6043301 41.1194534 ... 43.3375244 43.3375244 -33.7404442]]\n"
     ]
    }
   ],
   "source": [
    "tf.print(tf.shape(noise_x))\n",
    "noise_x_T, noise_z_T = tf.transpose(noise_x, (1,0)), tf.transpose(noise_z, (1,0))\n",
    "noise_x_int = tf.cast(noise_x_T, code.hz.dtype)\n",
    "noise_z_int = tf.cast(noise_z_T, code.hx.dtype)\n",
    "syndrome_x = int_mod_2(tf.matmul(code.hx, noise_z_int))\n",
    "syndrome_z = int_mod_2(tf.matmul(code.hz, noise_x_int))\n",
    "tf.print(tf.shape(syndrome_x))\n",
    "tf.print(syndrome_x)\n",
    "tf.print(syndrome_z)\n",
    "\n",
    "llr_ch_x = tf.fill(tf.shape(noise_x), tf.math.log(3.*(1.-p)/p))\n",
    "llr = tf.tile(tf.expand_dims(llr_ch_x, axis=1), multiples=tf.constant([1, 3, 1], tf.int32))\n",
    "\n",
    "llrx, llry, llrz, x_hat_stage_one, z_hat_stage_one, logit_hx_perp, logit_hz_perp = decoder_soft((llr, syndrome_x, syndrome_z))\n",
    "tf.print(\"llrx shape\", tf.shape(llrx))\n",
    "tf.print(llrx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b4590b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[116 882]\n",
      "[116 882]\n"
     ]
    }
   ],
   "source": [
    "num_hx = tf.math.softplus(-1.*llrx) # I or X, both commute with X-type check\n",
    "denom_hx = tf.ragged.map_flat_values(lambda x, y: tf.math.reduce_logsumexp(-1.*tf.stack([x, y], axis=-1), axis=-1), llrz, llry)\n",
    "new_llr_z = num_hx - denom_hx\n",
    "tf.print(tf.shape(new_llr_z))\n",
    "\n",
    "num_hz = tf.math.softplus(-1.*llrz) # I or Z, both commute with Z-type check\n",
    "denom_hz = tf.ragged.map_flat_values(lambda x, y: tf.math.reduce_logsumexp(-1.*tf.stack([x, y], axis=-1), axis=-1), llrx, llry)\n",
    "new_llr_x = num_hz - denom_hz\n",
    "tf.print(tf.shape(new_llr_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9e009216",
   "metadata": {},
   "outputs": [],
   "source": [
    "def osd0(llr, pcm, s):\n",
    "    # use llrz together with code.hx and syndrome_x, return noise_z_hat\n",
    "    sort_order = tf.argsort(llr)\n",
    "\n",
    "    permuted_pcm = tf.gather(pcm, sort_order, axis=1) \n",
    "\n",
    "    inv_sort = tf.math.invert_permutation(sort_order)\n",
    "    \n",
    "    row_ech_form, rank, transform, pivot_cols = row_echelon(permuted_pcm.numpy())\n",
    "    \n",
    "    new_pcm = tf.gather(permuted_pcm, pivot_cols, axis=1)\n",
    "    \n",
    "    syndrome = tf.expand_dims(s, 1)\n",
    "    \n",
    "    pcm_synd = tf.concat((new_pcm, syndrome), axis=1)\n",
    "    \n",
    "    row_ech_form, rank, _, _ = row_echelon(pcm_synd.numpy(), reduced=True)\n",
    "    \n",
    "#     tf.print(tf.shape(pivot_cols))\n",
    "#     tf.print(tf.shape(row_ech_form[:,-1]))\n",
    "    \n",
    "    e_hat = tf.tensor_scatter_nd_update(tf.zeros_like(llr, dtype=tf.bool), tf.expand_dims(pivot_cols, axis=1), row_ech_form[:,-1])\n",
    "    \n",
    "    e_hat = tf.gather(e_hat, inv_sort)\n",
    "    \n",
    "    return e_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6bfece7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[429 882]\n",
      "[429 882]\n",
      "[429 116]\n",
      "[429 116]\n"
     ]
    }
   ],
   "source": [
    "_, _, _, pivot_hx = row_echelon(code.hx.T)\n",
    "reduced_hx = tf.gather(code.hx, pivot_hx, axis=0) # select linearly independent rows\n",
    "tf.print(tf.shape(reduced_hx))\n",
    "\n",
    "_, _, _, pivot_hz = row_echelon(code.hz.T)\n",
    "reduced_hz = tf.gather(code.hz, pivot_hz, axis=0) # select linearly independent rows\n",
    "tf.print(tf.shape(reduced_hz))\n",
    "\n",
    "reduced_sx = tf.gather(syndrome_x, pivot_hx, axis=0)\n",
    "reduced_sz = tf.gather(syndrome_z, pivot_hz, axis=0)\n",
    "\n",
    "tf.print(tf.shape(reduced_sx))\n",
    "tf.print(tf.shape(reduced_sz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "76cbda05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[116 882]\n",
      "[116 882]\n"
     ]
    }
   ],
   "source": [
    "noise_z_hat_list, noise_x_hat_list = [], []\n",
    "bs = tf.shape(new_llr_z)[0]\n",
    "for i in range(bs):\n",
    "    noise_z_hat_list.append(osd0(new_llr_z[i], reduced_hx, reduced_sx[:,i]))\n",
    "    noise_x_hat_list.append(osd0(new_llr_x[i], reduced_hz, reduced_sz[:,i]))\n",
    "    \n",
    "noise_x_hat = tf.stack(noise_x_hat_list, axis=0)\n",
    "tf.print(tf.shape(noise_x_hat))\n",
    "noise_z_hat = tf.stack(noise_z_hat_list, axis=0)\n",
    "tf.print(tf.shape(noise_z_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ecfa4bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([882 116], shape=(2,), dtype=int32)\n",
      "tf.Tensor([882 116], shape=(2,), dtype=int32)\n",
      "tf.Tensor([116 882], shape=(2,), dtype=int32)\n",
      "tf.Tensor(40690, shape=(), dtype=int64)\n",
      "tf.Tensor(116, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "x_hat = tf.transpose(noise_x_hat, (1,0)) # [self.n, bs]\n",
    "z_hat = tf.transpose(noise_z_hat, (1,0))\n",
    "noise_x_T, noise_z_T = tf.transpose(noise_x, (1,0)), tf.transpose(noise_z, (1,0))\n",
    "print(tf.shape(noise_x_T))\n",
    "print(tf.shape(x_hat))\n",
    "\n",
    "x_diff = tf.cast(tf.math.logical_xor(noise_x_T, x_hat), code.hx_perp.dtype)\n",
    "z_diff = tf.cast(tf.math.logical_xor(noise_z_T, z_hat), code.hz_perp.dtype)\n",
    "\n",
    "sx = int_mod_2(tf.matmul(code.hz, x_diff))\n",
    "sz = int_mod_2(tf.matmul(code.hx, z_diff)) \n",
    "s_hat = tf.concat([sx, sz], axis=0)\n",
    "s_hat = tf.transpose(s_hat, (1,0))\n",
    "err = tf.reduce_any(tf.not_equal(tf.zeros_like(s_hat), s_hat), axis=-1)\n",
    "# OSD should clean up all flag errors\n",
    "\n",
    "lsx = int_mod_2(tf.matmul(code.hx_perp, x_diff))\n",
    "lsz = int_mod_2(tf.matmul(code.hz_perp, z_diff))\n",
    "\n",
    "ls_hat = tf.concat([lsx, lsz], axis=0)      # for total logical error counts\n",
    "ls_hat = tf.transpose(ls_hat, (1,0))         # bs should be the first dimension!!!\n",
    "logical_err = tf.reduce_any(tf.not_equal(tf.zeros_like(ls_hat), ls_hat), axis=-1)\n",
    "\n",
    "print(tf.shape(s_hat))\n",
    "print(tf.reduce_sum(s_hat))\n",
    "print(tf.reduce_sum(tf.cast(logical_err, dtype=tf.int32)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8d47f1",
   "metadata": {},
   "source": [
    "## Quaternary BP\n",
    "| CN update       | $p$  | $p_L$  |\n",
    "| --------------- | :-:  | :-:    |\n",
    "| SP, 1.0, 64     | 0.10 | 5.1e-3\n",
    "|                 | 0.09 | 1.74e-3\n",
    "|                 | 0.08 | 1.08e-3\n",
    "| NMS, 0.8, 100   | 0.10 | 2.8e-4\n",
    "|                 | 0.09 | 2e-5 (1/50000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24bd5100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        p |    Flagged |       BLER | flag errors | block errors |  num blocks | runtime [s] |    status\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "    0.067 | 1.0000e+00 | 1.0000e+00 |       10000 |        10000 |       10000 |         1.2 |reached target block errors\n",
      "     0.06 | 9.9730e-01 | 9.9730e-01 |        9973 |         9973 |       10000 |         0.2 |reached target block errors\n",
      "    0.053 | 9.8540e-01 | 9.8540e-01 |        9854 |         9854 |       10000 |         0.2 |reached target block errors\n",
      "    0.047 | 9.1680e-01 | 9.1680e-01 |        9168 |         9168 |       10000 |         0.2 |reached target block errors\n",
      "     0.04 | 7.0030e-01 | 7.0030e-01 |        7003 |         7003 |       10000 |         0.2 |reached target block errors\n",
      "    0.033 | 3.6040e-01 | 3.6040e-01 |        3604 |         3604 |       10000 |         0.2 |reached target block errors\n",
      "    0.027 | 1.0610e-01 | 1.0610e-01 |        1061 |         1061 |       10000 |         0.2 |reached target block errors\n",
      "     0.02 | 2.4100e-02 | 2.4100e-02 |         241 |          241 |       10000 |         0.2 |reached target block errors\n",
      "    0.013 | 7.0500e-03 | 7.0500e-03 |         141 |          141 |       20000 |         0.3 |reached target block errors\n",
      "    0.007 | 8.7692e-04 | 8.7692e-04 |         114 |          114 |      130000 |         2.2 |reached target block errors\n"
     ]
    }
   ],
   "source": [
    "code = GHP_n882_k24\n",
    "decoder = LDPCBPDecoder(code.hx, is_syndrome=True, num_iter=64, cn_type='minsum') # binary syndrome BP decoder\n",
    "# noise added by BSC channel\n",
    "model = BP_BSC_Model(pcm=code.hx, decoder=decoder, logical_pcm=code.hz_perp, p0=0.2) # p0 is used to initialize BP\n",
    "# If p0 is not specified (default set to None), then the actual p value employed for noise generation will be used for BP initialization.\n",
    "p_range = np.arange(0.01,0.101,0.01)[::-1] * 2/3 \n",
    "\n",
    "ber_plot = PlotBER(\"Performance of the [[882,24]] code on BSC channel under binary decoding\")\n",
    "\n",
    "ber_plot.simulate(model, \n",
    "                  ebno_dbs=p_range, # physical error rates to simulate\n",
    "                  legend=f\"{code.name}, factor={1.0}, iter={64}, p0=0.2\", # legend string for plotting\n",
    "                  max_mc_iter=1000, # run 1000 Monte Carlo runs per physical error rate point\n",
    "                  num_target_block_errors=100, # continue with next physical error rate point after 1000 block errors\n",
    "                  batch_size=10000, # batch-size per Monte Carlo run\n",
    "                  soft_estimates=False, # the model returns hard-estimates\n",
    "                  early_stop=True, # stop simulation if no error has been detected at current physical error rate\n",
    "                  show_fig=False, # do not show the figure after all results are simulated\n",
    "                  add_bler=True, # we are interested in block error rate\n",
    "                  qldpc=True, # show flagged error rate, instead of showing bit error rate\n",
    "                  forward_keyboard_interrupt=True); # should be True in a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd95a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BP2_BSC_Error_Model(tf.keras.Model):\n",
    "    def __init__(self, pcm, decoder, logical_pcm=None, p0=None):\n",
    "\n",
    "        super().__init__()\n",
    "        \n",
    "        # store values internally\n",
    "        self.pcm = pcm\n",
    "        self.logical_pcm = logical_pcm\n",
    "        _, self.n = pcm.shape\n",
    "        self.source = BinarySource()\n",
    "       \n",
    "        self.channel = BinarySymmetricChannel()\n",
    "\n",
    "        # FEC encoder / decoder\n",
    "        self.decoder = decoder\n",
    "        self.p0 = p0\n",
    "\n",
    "#     @tf.function(jit_compile=True, reduce_retracing=True) # XLA mode during evaluation\n",
    "    @tf.function() # graph mode\n",
    "    def call(self, batch_size, ebno_db):\n",
    "\n",
    "        p0 = ebno_db if self.p0 is None else self.p0\n",
    "        llr_const = -tf.math.log((1.-p0)/p0)\n",
    "           \n",
    "        c = tf.zeros([batch_size, self.n])\n",
    "        noise = self.channel((c, ebno_db))  # [bs, self.n]\n",
    "        llr = tf.fill(tf.shape(noise), llr_const)  \n",
    "        noise_int = tf.transpose(tf.cast(noise, self.pcm.dtype), (1,0)) # [self.n, bs]\n",
    "        syndrome = int_mod_2(tf.matmul(self.pcm, noise_int))\n",
    "        noise_hat = self.decoder((llr, syndrome)) \n",
    "\n",
    "        noise_hat = tf.transpose(tf.cast(noise_hat, self.pcm.dtype), (1,0)) # [self.n, bs]\n",
    "        noise_diff = tf.math.logical_xor(tf.cast(noise_int, tf.bool), tf.cast(noise_hat, tf.bool)) \n",
    "        noise_diff = tf.cast(noise_diff, self.pcm.dtype)\n",
    "        s_hat = int_mod_2(tf.matmul(self.pcm, noise_diff))\n",
    "        s_hat = tf.transpose(s_hat, (1,0)) # bs should be the first dimension!\n",
    "\n",
    "        err = tf.reduce_any(tf.not_equal(tf.zeros_like(s_hat), s_hat), axis=-1)\n",
    "        return noise[err]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a6515dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "physical error rate 0.03999999910593033, find BP failed-to-decode samples (flagged errors)\n"
     ]
    }
   ],
   "source": [
    "GHP_n882_k24 = create_QC_GHP_codes(63, create_cyclic_permuting_matrix(7, [27,54,0]), [0,1,6]) # 18 <= d <= 24\n",
    "code = GHP_n882_k24\n",
    "\n",
    "p = tf.constant(0.04)\n",
    "num_iter = 100\n",
    "factor = tf.constant(0.8)\n",
    "\n",
    "decoder_hard = LDPCBPDecoder(code.hx, cn_type=\"minsum\", is_syndrome=True, num_iter=num_iter, normalization_factor=factor, hard_out=True) # binary syndrome BP decoder\n",
    "decoder_soft = LDPCBPDecoder(code.hx, cn_type=\"minsum\", is_syndrome=True, num_iter=num_iter, normalization_factor=factor, hard_out=False) # binary syndrome BP decoder\n",
    "\n",
    "model = BP2_BSC_Error_Model(pcm=code.hx, decoder=decoder_hard, p0=p)\n",
    "\n",
    "batch_size = tf.constant(50000)\n",
    "\n",
    "print(f\"physical error rate {p}, find BP failed-to-decode samples (flagged errors)\")\n",
    "\n",
    "sample_list = []\n",
    "\n",
    "noise = model(batch_size, p)\n",
    "sample_list.append(noise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c45047d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1190 882]\n",
      "[441 1190]\n"
     ]
    }
   ],
   "source": [
    "noise = sample_list[0]\n",
    "tf.print(tf.shape(noise))\n",
    "noise_T = tf.transpose(noise, (1,0))\n",
    "noise_int = tf.cast(noise_T, code.hx.dtype)\n",
    "syndrome = int_mod_2(tf.matmul(code.hx, noise_int))\n",
    "tf.print(tf.shape(syndrome))\n",
    "\n",
    "llr = tf.fill(tf.shape(noise), -tf.math.log((1.-p)/p))\n",
    "llr_post = decoder_soft((llr, syndrome))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "28789edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[429 882]\n",
      "[429 1190]\n",
      "[1190 882]\n"
     ]
    }
   ],
   "source": [
    "_, _, _, pivot_hx = row_echelon(code.hx.T)\n",
    "reduced_hx = tf.gather(code.hx, pivot_hx, axis=0) # select linearly independent rows\n",
    "tf.print(tf.shape(reduced_hx))\n",
    "\n",
    "reduced_s = tf.gather(syndrome, pivot_hx, axis=0)\n",
    "\n",
    "tf.print(tf.shape(reduced_s))\n",
    "\n",
    "noise_hat_list = []\n",
    "bs = tf.shape(llr_post)[0]\n",
    "for i in range(bs):\n",
    "    noise_hat_list.append(osd0(-1.*llr_post[i], reduced_hx, reduced_s[:,i]))\n",
    "    \n",
    "noise_hat = tf.stack(noise_hat_list, axis=0)\n",
    "tf.print(tf.shape(noise_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "520cc590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 882 1190], shape=(2,), dtype=int32)\n",
      "tf.Tensor([ 882 1190], shape=(2,), dtype=int32)\n",
      "tf.Tensor([1190  441], shape=(2,), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "noise_hat = tf.transpose(noise_hat, (1,0)) # [self.n, bs]\n",
    "print(tf.shape(noise_T))\n",
    "print(tf.shape(noise_hat))\n",
    "noise_diff = tf.cast(tf.math.logical_xor(tf.cast(noise_T, tf.bool), noise_hat), code.hz_perp.dtype)\n",
    "\n",
    "s_hat = int_mod_2(tf.matmul(code.hx, noise_diff)) \n",
    "s_hat = tf.transpose(s_hat, (1,0))\n",
    "err = tf.reduce_any(tf.not_equal(tf.zeros_like(s_hat), s_hat), axis=-1)\n",
    "# OSD should clean up all flag errors\n",
    "\n",
    "ls_hat = int_mod_2(tf.matmul(code.hz_perp, noise_diff))\n",
    "\n",
    "ls_hat = tf.transpose(ls_hat, (1,0))         # bs should be the first dimension!!!\n",
    "logical_err = tf.reduce_any(tf.not_equal(tf.zeros_like(ls_hat), ls_hat), axis=-1)\n",
    "\n",
    "print(tf.shape(s_hat))\n",
    "print(tf.reduce_sum(s_hat))\n",
    "print(tf.reduce_sum(tf.cast(logical_err, dtype=tf.int32)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2961e27e",
   "metadata": {},
   "source": [
    "## Binary BP\n",
    "| CN update       | $p$  | $p_L$  |\n",
    "| --------------- | :-:  | :-:    |\n",
    "| NMS, 0.8, 100   | 0.05 | 6.4e-4\n",
    "| ^^              | 0.04 | 2e-5 (1/50000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
