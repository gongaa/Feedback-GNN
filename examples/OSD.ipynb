{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "027909e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available : 1\n",
      "Only GPU number 0 used.\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # INFO, WARNING messages are not printed\n",
    "import tensorflow as tf\n",
    "import time # for throughput measurements\n",
    "\n",
    "# Configure the notebook to use only a single GPU and allocate only as much memory as needed\n",
    "# For more details, see https://www.tensorflow.org/guide/gpu\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print('Number of GPUs available :', len(gpus))\n",
    "if gpus:\n",
    "    gpu_num = 0 # Number of the GPU to be used\n",
    "    try:\n",
    "        #tf.config.set_visible_devices([], 'GPU')\n",
    "        tf.config.set_visible_devices(gpus[gpu_num], 'GPU')\n",
    "        print('Only GPU number', gpu_num, 'used.')\n",
    "        tf.config.experimental.set_memory_growth(gpus[gpu_num], True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# uninstall sionna first\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(str(Path('..')))\n",
    "\n",
    "from sionna.fec.ldpc import *\n",
    "from sionna.utils import BinarySource \n",
    "from sionna.utils.metrics import count_block_errors\n",
    "from sionna.channel import Pauli, BinarySymmetricChannel\n",
    "from sionna.utils.plotting import PlotBER\n",
    "\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from sionna.utils.metrics import compute_bler\n",
    "from sionna.fec.utils import int_mod_2, row_echelon\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "431f4eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "GHP_n882_k24 = create_QC_GHP_codes(63, create_cyclic_permuting_matrix(7, [27,54,0]), [0,1,6]) # 18 <= d <= 24\n",
    "code = GHP_n882_k24\n",
    "\n",
    "num_iter = tf.constant(100)\n",
    "factor=tf.constant(0.8)\n",
    "\n",
    "bp4_decoder = QLDPCBPDecoder(code=code, num_iter=num_iter, normalization_factor=factor, cn_type=\"minsum\", trainable=False, stage_one=True)\n",
    "osd0_decoder = OSD0_Decoder(code.N)\n",
    "\n",
    "bp4_osd0_model = BP4_OSD_Model(code, bp4_decoder, osd0_decoder)\n",
    "\n",
    "bp2_decoder = LDPCBPDecoder(code.hx, is_syndrome=True, hard_out=False, cn_type=\"minsum\", num_iter=100, normalization_factor=factor)\n",
    "bp2_osd0_model = BP2_OSD_Model(code.hx, code.hx_basis, code.pivot_hx, code.lx, bp2_decoder, osd0_decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16c9abb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "      0.1 | 7.5139e-05 | 3.7000e-04 |        1082 |    14400000 |          111 |      300000 |        88.2 |reached target block errors\n",
      "     0.09 | 1.1973e-05 | 6.0000e-05 |         977 |    81600000 |          102 |     1700000 |       350.0 |reached target block errors\n",
      "     0.08 | 1.7424e-06 | 8.6580e-06 |         966 |   554400000 |          100 |    11550000 |      1845.9 |reached target block errors\n"
     ]
    }
   ],
   "source": [
    "p_range = np.arange(0.08,0.101,0.01)[::-1]\n",
    "\n",
    "ber_plot = PlotBER(\"Performance of the [[882,24]] code on Depolarizing channel under BP4+OSD0 Decoding\")\n",
    "\n",
    "ber_plot.simulate(bp4_osd0_model, \n",
    "                  ebno_dbs=p_range, # physical error rates to simulate\n",
    "                  legend=f\"{code.name}, factor={factor}, iter={num_iter}\", # legend string for plotting\n",
    "                  max_mc_iter=1000, # run 1000 Monte Carlo runs per physical error rate point\n",
    "                  num_target_block_errors=100, # continue with next physical error rate point after 1000 block errors\n",
    "                  batch_size=50000, # batch-size per Monte Carlo run\n",
    "                  soft_estimates=False, # the model returns hard-estimates\n",
    "                  early_stop=True, # stop simulation if no error has been detected at current physical error rate\n",
    "                  show_fig=False, # do not show the figure after all results are simulated\n",
    "                  add_bler=True, # we are interested in block error rate\n",
    "                  qldpc=False, # since there is no flagged error for bp-osd\n",
    "                  forward_keyboard_interrupt=True, # should be True in a loop\n",
    "                  graph_mode=None);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fc4da8c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "     0.05 | 2.1208e-04 | 5.8500e-04 |        1018 |     4800000 |          117 |      200000 |        43.6 |reached target block errors\n",
      "     0.04 | 7.1802e-06 | 2.3256e-05 |         741 |   103200000 |          100 |     4300000 |       515.9 |reached target block errors\n"
     ]
    }
   ],
   "source": [
    "p_range = np.arange(0.04,0.051,0.01)[::-1]\n",
    "\n",
    "ber_plot = PlotBER(\"Performance of the [[882,24]] code on BSC channel under BP2+OSD0 Decoding\")\n",
    "\n",
    "ber_plot.simulate(bp2_osd0_model, \n",
    "                  ebno_dbs=p_range, # physical error rates to simulate\n",
    "                  legend=f\"{code.name}, factor={factor}, iter={num_iter}\", # legend string for plotting\n",
    "                  max_mc_iter=1000, # run 1000 Monte Carlo runs per physical error rate point\n",
    "                  num_target_block_errors=100, # continue with next physical error rate point after 1000 block errors\n",
    "                  batch_size=50000, # batch-size per Monte Carlo run\n",
    "                  soft_estimates=False, # the model returns hard-estimates\n",
    "                  early_stop=True, # stop simulation if no error has been detected at current physical error rate\n",
    "                  show_fig=False, # do not show the figure after all results are simulated\n",
    "                  add_bler=True, # we are interested in block error rate\n",
    "                  qldpc=False, # since there is no flagged error for bp-osd\n",
    "                  forward_keyboard_interrupt=True, # should be True in a loop\n",
    "                  graph_mode=None);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86dee49d",
   "metadata": {},
   "source": [
    "## Compared with [BP+OSD](https://github.com/quantumgizmos/bp_osd/tree/main) on Github. Their code is written in Cython, the c++ component is [here](https://github.com/quantumgizmos/ldpc). The c++ part is not using AVX, but fast due to the [mod2sparse](https://github.com/quantumgizmos/ldpc/blob/1714314b1904c1430ae79b48be8a3c7015952bd5/src/ldpc/include/mod2sparse.c)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20ddd659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p=0.05, elapsed time: 60.73390205600299\n",
      "error rate: 0.00065\n",
      "p=0.04, elapsed time: 39.90716636599973\n",
      "error rate: 0.0001\n"
     ]
    }
   ],
   "source": [
    "from ldpc import bposd_decoder\n",
    "from bposd.css import css_code\n",
    "\n",
    "p = 0.05\n",
    "bpd=bposd_decoder(\n",
    "    code.hx,# the parity check matrix\n",
    "    error_rate=p,\n",
    "    channel_probs=[None], # assign error_rate to each qubit. This will override \"error_rate\" input variable\n",
    "    max_iter=100, # the maximum number of iterations for BP)\n",
    "    bp_method=\"ms\",\n",
    "    ms_scaling_factor=0.8, # min sum scaling factor. If set to zero the variable scaling factor method is used\n",
    "    osd_method=\"osd0\", # the OSD method. Choose from:  1) \"osd_e\", \"osd_cs\", \"osd0\"\n",
    "    osd_order=0 # the osd search depth\n",
    ")\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "num_err = 0\n",
    "num_samples = 100000\n",
    "for i in range(num_samples):\n",
    "    err = np. random.uniform(size=code.N) < p\n",
    "    syndrome = code.hx @ err % 2\n",
    "    bpd.decode(syndrome)\n",
    "    residual_error = (bpd.osdw_decoding + err) % 2\n",
    "    a = (code.lx @ residual_error % 2).any()\n",
    "    num_err += a\n",
    "end_time = time.perf_counter()\n",
    "print(f\"p={p}, elapsed time: {end_time-start_time}\")\n",
    "print(\"error rate:\", num_err/num_samples)\n",
    "\n",
    "p = 0.04\n",
    "bpd=bposd_decoder(\n",
    "    code.hx,# the parity check matrix\n",
    "    error_rate=p,\n",
    "    channel_probs=[None], # assign error_rate to each qubit. This will override \"error_rate\" input variable\n",
    "    max_iter=100, # the maximum number of iterations for BP)\n",
    "    bp_method=\"ms\",\n",
    "    ms_scaling_factor=0.8, # min sum scaling factor. If set to zero the variable scaling factor method is used\n",
    "    osd_method=\"osd0\", # the OSD method. Choose from:  1) \"osd_e\", \"osd_cs\", \"osd0\"\n",
    "    osd_order=0 # the osd search depth\n",
    ")\n",
    "start_time = time.perf_counter()\n",
    "num_err = 0\n",
    "num_samples = 100000\n",
    "for i in range(num_samples):\n",
    "    err = np. random.uniform(size=code.N) < p\n",
    "    syndrome = code.hx @ err % 2\n",
    "    bpd.decode(syndrome)\n",
    "    residual_error = (bpd.osdw_decoding + err) % 2\n",
    "    a = (code.lx @ residual_error % 2).any()\n",
    "    num_err += a\n",
    "end_time = time.perf_counter()\n",
    "print(f\"p={p}, elapsed time: {end_time-start_time}\")\n",
    "print(\"error rate:\", num_err/num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d1554f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 20 calls to <function BP4_Error_Model.call at 0x7f77924810d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "tf.Tensor(649, shape=(), dtype=int32)\n",
      "osd Elapsed time:  5.737122964113951\n",
      "osd Elapsed time:  3.777888922020793\n",
      "osd Elapsed time:  3.778188056079671\n",
      "bp Elapsed time:  3.194158664904535\n",
      "bp Elapsed time:  3.9569633579812944\n",
      "bp Elapsed time:  3.9650151561945677\n",
      "bp+osd Elapsed time:  11.926026392029598\n",
      "bp+osd Elapsed time:  9.959186625899747\n",
      "bp+osd Elapsed time:  9.73245100188069\n"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "\n",
    "GHP_n882_k24 = create_QC_GHP_codes(63, create_cyclic_permuting_matrix(7, [27,54,0]), [0,1,6]) # 18 <= d <= 24\n",
    "code = GHP_n882_k24\n",
    "# GHP_n1270_k28 = create_QC_GHP_codes(127, np.array([[0,-1,51,52,-1],[-1,0,-1,111,20],[0,-1,98,-1,122],[0,80,-1,119,-1],[-1,0,5,-1,106]]), [0,1,7], name=\"GHP_n1270_k28\") # 16 <= d <= 46\n",
    "# code = GHP_n1270_k28\n",
    "num_iter = tf.constant(120)\n",
    "factor=tf.constant(0.8)\n",
    "\n",
    "decoder_hard = QLDPCBPDecoder(code=code, num_iter=num_iter, normalization_factor=factor, cn_type=\"minsum\", trainable=False, stage_one=False)\n",
    "decoder_soft = QLDPCBPDecoder(code=code, num_iter=num_iter, normalization_factor=factor, cn_type=\"minsum\", trainable=False, stage_one=True)\n",
    "\n",
    "bp4_model = BP4_Error_Model(code, decoder_hard, num_iter=num_iter, trainable=False, wt=False)\n",
    "osd_model = OSD_Model(code, decoder_soft, num_iter=num_iter, trainable=False, wt=False)\n",
    "bp4_osd_model = BP4_OSD_Model(code, bp4_model, osd_model)\n",
    "batch_size = tf.constant(50000)\n",
    "p = tf.constant(0.09)\n",
    "\n",
    "noise_x, noise_z, x_hat, z_hat, err = bp4_model(batch_size, p)\n",
    "nx, nz = noise_x[err], noise_z[err]\n",
    "new_bs = tf.reduce_sum(tf.cast(err, tf.int32))\n",
    "# x_hat_osd, z_hat_osd = osd_model(nx, nz, ebno_db, new_bs)\n",
    "print(new_bs)\n",
    "for i in range(3):\n",
    "    start_time = time.perf_counter()\n",
    "    osd_model(nx, nz, p, new_bs)\n",
    "    end_time = time.perf_counter()\n",
    "    print(\"osd Elapsed time: \", end_time-start_time)\n",
    "\n",
    "for i in range(3):\n",
    "    start_time = time.perf_counter()\n",
    "    bp4_model(batch_size, p)\n",
    "    end_time = time.perf_counter()\n",
    "    print(\"bp Elapsed time: \", end_time-start_time)\n",
    "    \n",
    "for i in range(3):\n",
    "    start_time = time.perf_counter()\n",
    "    bp4_osd_model(batch_size, p)\n",
    "    end_time = time.perf_counter()\n",
    "    print(\"bp+osd Elapsed time: \", end_time-start_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8d47f1",
   "metadata": {},
   "source": [
    "## Quaternary BP\n",
    "| CN update       | $p$  | $p_L$  |\n",
    "| --------------- | :-:  | :-:    |\n",
    "| SP, 1.0, 64     | 0.10 | 5.1e-3\n",
    "|                 | 0.09 | 1.74e-3\n",
    "|                 | 0.08 | 1.08e-3\n",
    "| NMS, 0.8, 100   | 0.10 | 2.8e-4\n",
    "|                 | 0.09 | 2e-5 (1/50000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2961e27e",
   "metadata": {},
   "source": [
    "## Binary BP\n",
    "| CN update       | $p$  | $p_L$  |\n",
    "| --------------- | :-:  | :-:    |\n",
    "| NMS, 0.8, 100   | 0.05 | 6.4e-4\n",
    "| ^^              | 0.04 | 2e-5 (1/50000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
