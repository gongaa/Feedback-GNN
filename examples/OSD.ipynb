{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f049f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available : 1\n",
      "Only GPU number 0 used.\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # INFO, WARNING messages are not printed\n",
    "import tensorflow as tf\n",
    "import time # for throughput measurements\n",
    "\n",
    "# Configure the notebook to use only a single GPU and allocate only as much memory as needed\n",
    "# For more details, see https://www.tensorflow.org/guide/gpu\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print('Number of GPUs available :', len(gpus))\n",
    "if gpus:\n",
    "    gpu_num = 0 # Number of the GPU to be used\n",
    "    try:\n",
    "        #tf.config.set_visible_devices([], 'GPU')\n",
    "        tf.config.set_visible_devices(gpus[gpu_num], 'GPU')\n",
    "        print('Only GPU number', gpu_num, 'used.')\n",
    "        tf.config.experimental.set_memory_growth(gpus[gpu_num], True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# uninstall sionna first\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(str(Path('..')))\n",
    "\n",
    "from sionna.fec.ldpc import *\n",
    "from sionna.utils import BinarySource \n",
    "from sionna.utils.metrics import count_block_errors\n",
    "from sionna.channel import Pauli\n",
    "from sionna.utils.plotting import PlotBER\n",
    "\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from sionna.utils.metrics import compute_bler\n",
    "from sionna.fec.utils import int_mod_2, row_echelon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b831348",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BP4_Error_Model(tf.keras.Model):\n",
    "# For storing error strings that the BP decoder failed to decode\n",
    "    def __init__(self, code, decoder, num_iter=32, trainable=False, loss_type=\"boxplus-phi\", wt=False):\n",
    "\n",
    "        super().__init__()\n",
    "        \n",
    "        self.k = code.K      \n",
    "        self.n = code.N\n",
    "        self.hx = code.hx\n",
    "        self.hz = code.hz\n",
    "        self.lx = code.lx\n",
    "        self.lz = code.lz\n",
    "        self.hx_perp = code.hx_perp # contains Im(hz.T)\n",
    "        self.hz_perp = code.hz_perp # contains Im(hx.T)\n",
    "        self.code_name = code.name\n",
    "        self.num_checks = code.hx.shape[0] + code.hz.shape[0]\n",
    "        \n",
    "        self.source = BinarySource()\n",
    "        self.channel = Pauli(wt=wt)\n",
    "        self.decoder = decoder\n",
    "\n",
    "        self.num_iter = num_iter\n",
    "        self.trainable = trainable\n",
    "        self.bce = BinaryCrossentropy(from_logits=True)\n",
    "        self.loss_type = loss_type\n",
    "        self.wt = wt\n",
    "           \n",
    "#     @tf.function(jit_compile=True, reduce_retracing=True) # XLA mode\n",
    "    @tf.function() # graph mode\n",
    "    def call(self, batch_size, ebno_db):\n",
    "\n",
    "        p = ebno_db\n",
    "\n",
    "        # depolarizing noise\n",
    "        px, py, pz = 2*p/3, p/3, 2*p/3\n",
    "        c_dummy = tf.zeros([batch_size, self.n])\n",
    "        if self.wt: # ebno_db is an integer indicating the weight of the error\n",
    "            noise_x, noise_z = self.channel([c_dummy, None, p])\n",
    "        else:\n",
    "            noise_x, noise_z = self.channel([c_dummy, None, px, py, pz])  # [bs, self.n]\n",
    "        noise_x_T, noise_z_T = tf.transpose(noise_x, (1,0)), tf.transpose(noise_z, (1,0))\n",
    "        noise_x_int = tf.cast(noise_x_T, self.hz.dtype)\n",
    "        noise_z_int = tf.cast(noise_z_T, self.hx.dtype)\n",
    "        syndrome_x = int_mod_2(tf.matmul(self.hx, noise_z_int))\n",
    "        syndrome_z = int_mod_2(tf.matmul(self.hz, noise_x_int))\n",
    "\n",
    "        p0 = 0.05 \n",
    "        llr_ch_x = tf.fill(tf.shape(noise_x), tf.math.log(3.*(1.-p0)/p0))\n",
    "        llr = tf.tile(tf.expand_dims(llr_ch_x, axis=1), multiples=tf.constant([1, 3, 1], tf.int32))\n",
    "        # shape of llr: [bs, 3, self.n]\n",
    "        \n",
    "        x_hat, z_hat = self.decoder((llr, syndrome_x, syndrome_z))\n",
    "        \n",
    "        x_hat = tf.transpose(tf.cast(x_hat, tf.bool), (1,0)) # [self.n, bs]\n",
    "        z_hat = tf.transpose(tf.cast(z_hat, tf.bool), (1,0))\n",
    "\n",
    "        x_diff = tf.cast(tf.math.logical_xor(noise_x_T, x_hat), self.hx_perp.dtype)\n",
    "        z_diff = tf.cast(tf.math.logical_xor(noise_z_T, z_hat), self.hz_perp.dtype)\n",
    "\n",
    "        sx = int_mod_2(tf.matmul(self.hz, x_diff))\n",
    "        sz = int_mod_2(tf.matmul(self.hx, z_diff))\n",
    "        s_hat = tf.concat([sx, sz], axis=0)\n",
    "        s_hat = tf.transpose(s_hat, (1,0))\n",
    "        err = tf.reduce_any(tf.not_equal(tf.zeros_like(s_hat), s_hat), axis=-1)\n",
    "        return noise_x[err], noise_z[err]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "296f98a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "GHP_n882_k24 = create_QC_GHP_codes(63, create_cyclic_permuting_matrix(7, [27,54,0]), [0,1,6]) # 18 <= d <= 24\n",
    "code = GHP_n882_k24\n",
    "# GHP_n1270_k28 = create_QC_GHP_codes(127, np.array([[0,-1,51,52,-1],[-1,0,-1,111,20],[0,-1,98,-1,122],[0,80,-1,119,-1],[-1,0,5,-1,106]]), [0,1,7], name=\"GHP_n1270_k28\") # 16 <= d <= 46\n",
    "# code = GHP_n1270_k28\n",
    "num_iter = tf.constant(100)\n",
    "# decoder = QLDPCBPDecoder(code=code, num_iter=num_iter, normalization_factor=1.0, cn_type=\"boxplus-phi\")\n",
    "decoder = QLDPCBPDecoder(code=code, num_iter=num_iter, normalization_factor=0.9, cn_type=\"minsum\")\n",
    "model = BP4_Error_Model(code, decoder, num_iter=num_iter, trainable=False, wt=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "85359382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "physical error rate 0.08, find BP failed-to-decode samples (flagged errors)\n"
     ]
    }
   ],
   "source": [
    "# Run this cell multiple times\n",
    "batch_size = tf.constant(50000)\n",
    "p = 0.08\n",
    "\n",
    "print(f\"physical error rate {p}, find BP failed-to-decode samples (flagged errors)\")\n",
    "\n",
    "sample_x_list = []\n",
    "sample_z_list = []\n",
    "\n",
    "noise_x, noise_z = model(batch_size, tf.constant(p))\n",
    "sample_x_list.append(noise_x)\n",
    "sample_z_list.append(noise_z)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "700113e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1013 882]\n",
      "[441 1013]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "decoder1 = QLDPCBPDecoder(code=code, num_iter=num_iter, normalization_factor=1.0, cn_type=\"boxplus-phi\", trainable=False, stage_one=True)\n",
    "noise_x, noise_z = sample_x_list[0], sample_z_list[0]\n",
    "tf.print(tf.shape(noise_x))\n",
    "noise_x_T, noise_z_T = tf.transpose(noise_x, (1,0)), tf.transpose(noise_z, (1,0))\n",
    "noise_x_int = tf.cast(noise_x_T, code.hz.dtype)\n",
    "noise_z_int = tf.cast(noise_z_T, code.hx.dtype)\n",
    "syndrome_x = int_mod_2(tf.matmul(code.hx, noise_z_int))\n",
    "syndrome_z = int_mod_2(tf.matmul(code.hz, noise_x_int))\n",
    "tf.print(tf.shape(syndrome_x))\n",
    "p0 = 0.05 \n",
    "llr_ch_x = tf.fill(tf.shape(noise_x), tf.math.log(3.*(1.-p0)/p0))\n",
    "llr = tf.tile(tf.expand_dims(llr_ch_x, axis=1), multiples=tf.constant([1, 3, 1], tf.int32))\n",
    "\n",
    "llrx, llry, llrz, x_hat_stage_one, z_hat_stage_one, logit_hx_perp, logit_hz_perp = decoder1((llr, syndrome_x, syndrome_z))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19fddfd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1013 882]\n",
      "[1013 882]\n"
     ]
    }
   ],
   "source": [
    "num_hx = tf.math.softplus(-1.*llrx) # I or X, both commute with X-type check\n",
    "denom_hx = tf.ragged.map_flat_values(lambda x, y: tf.math.reduce_logsumexp(-1.*tf.stack([x, y], axis=-1), axis=-1), llrz, llry)\n",
    "new_llr_z = num_hx - denom_hx\n",
    "tf.print(tf.shape(new_llr_z))\n",
    "\n",
    "num_hz = tf.math.softplus(-1.*llrz) # I or Z, both commute with Z-type check\n",
    "denom_hz = tf.ragged.map_flat_values(lambda x, y: tf.math.reduce_logsumexp(-1.*tf.stack([x, y], axis=-1), axis=-1), llrx, llry)\n",
    "new_llr_x = num_hz - denom_hz\n",
    "tf.print(tf.shape(new_llr_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "434aaf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def osd0(llr, pcm, s):\n",
    "    # use llrz together with code.hx and syndrome_x, return noise_z_hat\n",
    "    sort_order = tf.argsort(llr)\n",
    "\n",
    "    permuted_pcm = tf.gather(pcm, sort_order, axis=1) \n",
    "\n",
    "    inv_sort = tf.math.invert_permutation(sort_order)\n",
    "    \n",
    "    row_ech_form, rank, transform, pivot_cols = row_echelon(permuted_pcm.numpy())\n",
    "    \n",
    "    new_pcm = tf.gather(permuted_pcm, pivot_cols, axis=1)\n",
    "    \n",
    "    syndrome = tf.expand_dims(s, 1)\n",
    "    \n",
    "    pcm_synd = tf.concat((new_pcm, syndrome), axis=1)\n",
    "    \n",
    "    row_ech_form, rank, _, _ = row_echelon(pcm_synd.numpy(), reduced=True)\n",
    "    \n",
    "#     tf.print(tf.shape(pivot_cols))\n",
    "#     tf.print(tf.shape(row_ech_form[:,-1]))\n",
    "    \n",
    "    e_hat = tf.tensor_scatter_nd_update(tf.zeros_like(llr, dtype=tf.bool), tf.expand_dims(pivot_cols, axis=1), row_ech_form[:,-1])\n",
    "    \n",
    "    e_hat = tf.gather(e_hat, inv_sort)\n",
    "    \n",
    "    return e_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9d37f54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[429 882]\n",
      "[429 882]\n",
      "[429 1013]\n",
      "[429 1013]\n"
     ]
    }
   ],
   "source": [
    "_, _, _, pivot_hx = row_echelon(code.hx.T)\n",
    "reduced_hx = tf.gather(code.hx, pivot_hx, axis=0) # select linearly independent rows\n",
    "tf.print(tf.shape(reduced_hx))\n",
    "\n",
    "_, _, _, pivot_hz = row_echelon(code.hz.T)\n",
    "reduced_hz = tf.gather(code.hz, pivot_hz, axis=0) # select linearly independent rows\n",
    "tf.print(tf.shape(reduced_hz))\n",
    "\n",
    "reduced_sx = tf.gather(syndrome_x, pivot_hx, axis=0)\n",
    "reduced_sz = tf.gather(syndrome_z, pivot_hz, axis=0)\n",
    "\n",
    "tf.print(tf.shape(reduced_sx))\n",
    "tf.print(tf.shape(reduced_sz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e29e5e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_z_hat_list, noise_x_hat_list = [], []\n",
    "bs = tf.shape(new_llr_z)[0]\n",
    "for i in range(bs):\n",
    "    noise_z_hat_list.append(osd0(new_llr_z[i], reduced_hx, reduced_sx[:,i]))\n",
    "    noise_x_hat_list.append(osd0(new_llr_x[i], reduced_hz, reduced_sz[:,i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e345e3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1013 882]\n",
      "[1013 882]\n"
     ]
    }
   ],
   "source": [
    "noise_x_hat = tf.stack(noise_x_hat_list, axis=0)\n",
    "tf.print(tf.shape(noise_x_hat))\n",
    "noise_z_hat = tf.stack(noise_z_hat_list, axis=0)\n",
    "tf.print(tf.shape(noise_z_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e83d44a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 882 1013], shape=(2,), dtype=int32)\n",
      "tf.Tensor([ 882 1013], shape=(2,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "x_hat = tf.transpose(noise_x_hat, (1,0)) # [self.n, bs]\n",
    "z_hat = tf.transpose(noise_z_hat, (1,0))\n",
    "\n",
    "print(tf.shape(noise_x_T))\n",
    "print(tf.shape(x_hat))\n",
    "\n",
    "x_diff = tf.cast(tf.math.logical_xor(noise_x_T, x_hat), code.hx_perp.dtype)\n",
    "z_diff = tf.cast(tf.math.logical_xor(noise_z_T, z_hat), code.hz_perp.dtype)\n",
    "\n",
    "sx = int_mod_2(tf.matmul(code.hz, x_diff))\n",
    "sz = int_mod_2(tf.matmul(code.hx, z_diff)) \n",
    "s_hat = tf.concat([sx, sz], axis=0)\n",
    "s_hat = tf.transpose(s_hat, (1,0))\n",
    "err = tf.reduce_any(tf.not_equal(tf.zeros_like(s_hat), s_hat), axis=-1)\n",
    "# OSD should clean up all flag errors\n",
    "\n",
    "lsx = int_mod_2(tf.matmul(code.hx_perp, x_diff))\n",
    "lsz = int_mod_2(tf.matmul(code.hz_perp, z_diff))\n",
    "\n",
    "ls_hat = tf.concat([lsx, lsz], axis=0)      # for total logical error counts\n",
    "ls_hat = tf.transpose(ls_hat, (1,0))         # bs should be the first dimension!!!\n",
    "logical_err = tf.reduce_any(tf.not_equal(tf.zeros_like(ls_hat), ls_hat), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "70b877f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1013  882], shape=(2,), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.shape(s_hat))\n",
    "print(tf.reduce_sum(s_hat))\n",
    "print(tf.reduce_sum(tf.cast(logical_err, dtype=tf.int32)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79988f35",
   "metadata": {},
   "source": [
    "BP: flooding, sum-product, no normalization.\n",
    "| CN update       | $p$  | $p_L$  |\n",
    "| --------------- | :-:  | :-:    |\n",
    "| SP, 1.0, 64     | 0.1  | 5.1e-3\n",
    "| ^^              | 0.09 | 1.74e-3\n",
    "| ^^              | 0.08 | 1.08e-3\n",
    "| MS, 1.0, 64     | 0.1 | 4.74e-3\n",
    "| NMS, 0.625, 100 | 0.08 | 5.4e-4\n",
    "| NMS, 0.8, 100   | 0.08 | 4e-5 (2/50000)\n",
    "| NMS, 0.9, 100   | 0.08 | 8e-5 (4/50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a07febc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generalized Bicycle Codes\n",
    "GB_n254_k28 = create_generalized_bicycle_codes(127, [0,15,20,28,66], [0,58,59,100,121]) # 14 <= d <= 20\n",
    "GB_n126_k28_d8 = create_generalized_bicycle_codes(63, [0,1,14,16,22], [0,3,13,20,42], name=\"GB_n126_k28_d8\")\n",
    "\n",
    "GB_n48_k6_d8 = create_generalized_bicycle_codes(24, [0,2,8,15], [0,2,12,17], name=\"GB_n48_k6_d8\")\n",
    "# create the code using the overcomplete check matrices in [2]\n",
    "GB_n48_pcm = readAlist('../sionna/fec/ldpc/codes_q/GB_48_6_H_2000.alist')\n",
    "GB_n48_k6_d8_oc = css_code(hx=GB_n48_pcm[:1000], hz=GB_n48_pcm[1000:], name=None, name_prefix=\"GB\")\n",
    "GB_n48_k6_d8_oc.name += \"_oc\"\n",
    "\n",
    "GB_n46_k2_d9 = create_generalized_bicycle_codes(23, [0,5,8,12], [0,1,5,7], name=\"GB_n46_k2_d9\")\n",
    "# create the code using the overcomplete check matrices in [2]\n",
    "GB_n46_pcm = readAlist('../sionna/fec/ldpc/codes_q/GB_46_2_H_800.alist')\n",
    "GB_n46_k2_d9_oc = css_code(hx=GB_n46_pcm[:400], hz=GB_n46_pcm[400:], name=None, name_prefix=\"GB\")\n",
    "GB_n46_k2_d9_oc.name += \"_oc\"\n",
    "\n",
    "GB_n180_n10 = create_generalized_bicycle_codes(90, [0,28,80,89], [0,2,21,25]) # 15 <= d <= 18\n",
    "GB_n900_k50_d15 = create_generalized_bicycle_codes(450, [0,97,372,425], [0,50,265,390], name=\"GB_n900_k50_d15\")\n",
    "\n",
    "# Hypergraph Product Codes\n",
    "# HP_n7935_n578_H = create_circulant_matrix(63, [0,3,34,41,57]) \n",
    "# HP_n7935_n578_d16 = hypergraph_product(HP_n7935_n578_H, HP_n7935_n578_H, name=\"HP_n7935_n578_d16\") # takes 40 seconds\n",
    "HP_n1922_k50_H = create_circulant_matrix(31, [0,2,5])\n",
    "HP_n1922_n50_d16 = hypergraph_product(HP_n1922_k50_H, HP_n1922_k50_H, name=\"HP_n1922_k50_d16\")\n",
    "\n",
    "# Generalized Hypergraph Product Codes\n",
    "GHP_n882_k24 = create_QC_GHP_codes(63, create_cyclic_permuting_matrix(7, [27,54,0]), [0,1,6]) # 18 <= d <= 24\n",
    "GHP_n882_k48_d16 = create_QC_GHP_codes(63, create_cyclic_permuting_matrix(7, [27,0,27,18,0]), [0,1,6], name=\"GHP_n882_k48_d16\")\n",
    "GHP_n1270_k28 = create_QC_GHP_codes(127, np.array([[0,-1,51,52,-1],[-1,0,-1,111,20],[0,-1,98,-1,122],[0,80,-1,119,-1],[-1,0,5,-1,106]]), [0,1,7], name=\"GHP_n1270_k28\") # 16 <= d <= 46\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24bd5100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        p |    Flagged |       BLER | flag errors | block errors |  num blocks | runtime [s] |    status\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "    0.067 | 8.6010e-01 | 8.6010e-01 |        8601 |         8601 |       10000 |         2.2 |reached target block errors\n",
      "     0.06 | 6.2610e-01 | 6.2610e-01 |        6261 |         6261 |       10000 |         0.1 |reached target block errors\n",
      "    0.053 | 3.0940e-01 | 3.0940e-01 |        3094 |         3094 |       10000 |         0.1 |reached target block errors\n",
      "    0.047 | 8.1000e-02 | 8.1000e-02 |         810 |          810 |       10000 |         0.1 |reached target block errors\n",
      "     0.04 | 8.8000e-03 | 8.8000e-03 |         176 |          176 |       20000 |         0.2 |reached target block errors\n",
      "    0.033 | 5.6667e-04 | 5.6667e-04 |         102 |          102 |      180000 |         2.2 |reached target block errors\n",
      "    0.027 | 2.8571e-04 | 2.8571e-04 |         100 |          100 |      350000 |         4.3 |reached target block errors\n",
      "     0.02 | 1.9608e-04 | 1.9608e-04 |         100 |          100 |      510000 |         6.2 |reached target block errors\n",
      "    0.013 | 1.6949e-04 | 1.6949e-04 |         100 |          100 |      590000 |         7.1 |reached target block errors\n",
      "    0.007 | 7.4627e-05 | 7.4627e-05 |         100 |          100 |     1340000 |        16.2 |reached target block errors\n"
     ]
    }
   ],
   "source": [
    "code = GHP_n882_k24\n",
    "decoder = LDPCBPDecoder(code.hx, is_syndrome=True, num_iter=64) # binary syndrome BP decoder\n",
    "# noise added by BSC channel\n",
    "model = BP_BSC_Model(pcm=code.hx, decoder=decoder, logical_pcm=code.hz_perp, p0=0.2) # p0 is used to initialize BP\n",
    "# If p0 is not specified (default set to None), then the actual p value employed for noise generation will be used for BP initialization.\n",
    "p_range = np.arange(0.01,0.101,0.01)[::-1] * 2/3 \n",
    "\n",
    "ber_plot = PlotBER(\"Performance of the [[882,24]] code on BSC channel under binary decoding\")\n",
    "\n",
    "ber_plot.simulate(model, \n",
    "                  ebno_dbs=p_range, # physical error rates to simulate\n",
    "                  legend=f\"{code.name}, factor={1.0}, iter={64}, p0=0.2\", # legend string for plotting\n",
    "                  max_mc_iter=1000, # run 1000 Monte Carlo runs per physical error rate point\n",
    "                  num_target_block_errors=100, # continue with next physical error rate point after 1000 block errors\n",
    "                  batch_size=10000, # batch-size per Monte Carlo run\n",
    "                  soft_estimates=False, # the model returns hard-estimates\n",
    "                  early_stop=True, # stop simulation if no error has been detected at current physical error rate\n",
    "                  show_fig=False, # do not show the figure after all results are simulated\n",
    "                  add_bler=True, # we are interested in block error rate\n",
    "                  qldpc=True, # show flagged error rate, instead of showing bit error rate\n",
    "                  forward_keyboard_interrupt=True); # should be True in a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6515dcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
