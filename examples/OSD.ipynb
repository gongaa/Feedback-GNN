{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "027909e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available : 1\n",
      "Only GPU number 0 used.\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # INFO, WARNING messages are not printed\n",
    "import tensorflow as tf\n",
    "import time # for throughput measurements\n",
    "\n",
    "# Configure the notebook to use only a single GPU and allocate only as much memory as needed\n",
    "# For more details, see https://www.tensorflow.org/guide/gpu\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print('Number of GPUs available :', len(gpus))\n",
    "if gpus:\n",
    "    gpu_num = 0 # Number of the GPU to be used\n",
    "    try:\n",
    "        #tf.config.set_visible_devices([], 'GPU')\n",
    "        tf.config.set_visible_devices(gpus[gpu_num], 'GPU')\n",
    "        print('Only GPU number', gpu_num, 'used.')\n",
    "        tf.config.experimental.set_memory_growth(gpus[gpu_num], True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# uninstall sionna first\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(str(Path('..')))\n",
    "\n",
    "from sionna.fec.ldpc import *\n",
    "from sionna.utils import BinarySource \n",
    "from sionna.utils.metrics import count_block_errors\n",
    "from sionna.channel import Pauli, BinarySymmetricChannel\n",
    "from sionna.utils.plotting import PlotBER\n",
    "\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from sionna.utils.metrics import compute_bler\n",
    "from sionna.fec.utils import int_mod_2, row_echelon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "431f4eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BP4_Error_Model(tf.keras.Model):\n",
    "# For storing error strings that the BP decoder failed to decode\n",
    "    def __init__(self, code, decoder, num_iter=32, trainable=False, loss_type=\"boxplus-phi\", wt=False):\n",
    "\n",
    "        super().__init__()\n",
    "        \n",
    "        self.k = code.K      \n",
    "        self.n = code.N\n",
    "        self.hx = code.hx\n",
    "        self.hz = code.hz\n",
    "        self.lx = code.lx\n",
    "        self.lz = code.lz\n",
    "        self.hx_perp = code.hx_perp # contains Im(hz.T)\n",
    "        self.hz_perp = code.hz_perp # contains Im(hx.T)\n",
    "        self.code_name = code.name\n",
    "        self.num_checks = code.hx.shape[0] + code.hz.shape[0]\n",
    "        \n",
    "        self.source = BinarySource()\n",
    "        self.channel = Pauli(wt=wt)\n",
    "        self.decoder = decoder\n",
    "\n",
    "        self.num_iter = num_iter\n",
    "        self.trainable = trainable\n",
    "        self.bce = BinaryCrossentropy(from_logits=True)\n",
    "        self.loss_type = loss_type\n",
    "        self.wt = wt\n",
    "           \n",
    "#     @tf.function(jit_compile=True, reduce_retracing=True) # XLA mode\n",
    "    @tf.function() # graph mode\n",
    "    def call(self, batch_size, ebno_db):\n",
    "\n",
    "        p = ebno_db\n",
    "\n",
    "        # depolarizing noise\n",
    "        px, py, pz = 2*p/3, p/3, 2*p/3\n",
    "        c_dummy = tf.zeros([batch_size, self.n])\n",
    "        if self.wt: # ebno_db is an integer indicating the weight of the error\n",
    "            noise_x, noise_z = self.channel([c_dummy, None, p])\n",
    "        else:\n",
    "            noise_x, noise_z = self.channel([c_dummy, None, px, py, pz])  # [bs, self.n]\n",
    "        noise_x_T, noise_z_T = tf.transpose(noise_x, (1,0)), tf.transpose(noise_z, (1,0))\n",
    "        noise_x_int = tf.cast(noise_x_T, self.hz.dtype)\n",
    "        noise_z_int = tf.cast(noise_z_T, self.hx.dtype)\n",
    "        syndrome_x = int_mod_2(tf.matmul(self.hx, noise_z_int))\n",
    "        syndrome_z = int_mod_2(tf.matmul(self.hz, noise_x_int))\n",
    "\n",
    "        p0 = 0.05 \n",
    "        llr_ch_x = tf.fill(tf.shape(noise_x), tf.math.log(3.*(1.-p0)/p0))\n",
    "        llr = tf.tile(tf.expand_dims(llr_ch_x, axis=1), multiples=tf.constant([1, 3, 1], tf.int32))\n",
    "        # shape of llr: [bs, 3, self.n]\n",
    "        \n",
    "        x_hat, z_hat = self.decoder((llr, syndrome_x, syndrome_z))\n",
    "        \n",
    "        x_hat = tf.transpose(tf.cast(x_hat, tf.bool), (1,0)) # [self.n, bs]\n",
    "        z_hat = tf.transpose(tf.cast(z_hat, tf.bool), (1,0))\n",
    "\n",
    "        x_diff = tf.cast(tf.math.logical_xor(noise_x_T, x_hat), self.hx_perp.dtype)\n",
    "        z_diff = tf.cast(tf.math.logical_xor(noise_z_T, z_hat), self.hz_perp.dtype)\n",
    "\n",
    "        sx = int_mod_2(tf.matmul(self.hz, x_diff))\n",
    "        sz = int_mod_2(tf.matmul(self.hx, z_diff))\n",
    "        s_hat = tf.concat([sx, sz], axis=0)\n",
    "        s_hat = tf.transpose(s_hat, (1,0))\n",
    "        err = tf.reduce_any(tf.not_equal(tf.zeros_like(s_hat), s_hat), axis=-1)\n",
    "        return noise_x[err], noise_z[err]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d1554f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "physical error rate 0.09000000357627869, find BP failed-to-decode samples (flagged errors)\n"
     ]
    }
   ],
   "source": [
    "GHP_n882_k24 = create_QC_GHP_codes(63, create_cyclic_permuting_matrix(7, [27,54,0]), [0,1,6]) # 18 <= d <= 24\n",
    "code = GHP_n882_k24\n",
    "# GHP_n1270_k28 = create_QC_GHP_codes(127, np.array([[0,-1,51,52,-1],[-1,0,-1,111,20],[0,-1,98,-1,122],[0,80,-1,119,-1],[-1,0,5,-1,106]]), [0,1,7], name=\"GHP_n1270_k28\") # 16 <= d <= 46\n",
    "# code = GHP_n1270_k28\n",
    "num_iter = tf.constant(100)\n",
    "factor=tf.constant(0.8)\n",
    "\n",
    "decoder_hard = QLDPCBPDecoder(code=code, num_iter=num_iter, normalization_factor=factor, cn_type=\"minsum\")\n",
    "decoder_soft = QLDPCBPDecoder(code=code, num_iter=num_iter, normalization_factor=factor, cn_type=\"minsum\", trainable=False, stage_one=True)\n",
    "\n",
    "model = BP4_Error_Model(code, decoder_hard, num_iter=num_iter, trainable=False, wt=False)\n",
    "\n",
    "# Run this cell multiple times\n",
    "batch_size = tf.constant(50000)\n",
    "p = tf.constant(0.09)\n",
    "\n",
    "print(f\"physical error rate {p}, find BP failed-to-decode samples (flagged errors)\")\n",
    "\n",
    "sample_x_list = []\n",
    "sample_z_list = []\n",
    "\n",
    "noise_x, noise_z = model(batch_size, p)\n",
    "sample_x_list.append(noise_x)\n",
    "sample_z_list.append(noise_z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6355c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1151 882]\n",
      "[441 1151]\n"
     ]
    }
   ],
   "source": [
    "noise_x, noise_z = sample_x_list[0], sample_z_list[0]\n",
    "tf.print(tf.shape(noise_x))\n",
    "noise_x_T, noise_z_T = tf.transpose(noise_x, (1,0)), tf.transpose(noise_z, (1,0))\n",
    "noise_x_int = tf.cast(noise_x_T, code.hz.dtype)\n",
    "noise_z_int = tf.cast(noise_z_T, code.hx.dtype)\n",
    "syndrome_x = int_mod_2(tf.matmul(code.hx, noise_z_int))\n",
    "syndrome_z = int_mod_2(tf.matmul(code.hz, noise_x_int))\n",
    "tf.print(tf.shape(syndrome_x))\n",
    "\n",
    "llr_ch_x = tf.fill(tf.shape(noise_x), tf.math.log(3.*(1.-p)/p))\n",
    "llr = tf.tile(tf.expand_dims(llr_ch_x, axis=1), multiples=tf.constant([1, 3, 1], tf.int32))\n",
    "\n",
    "llrx, llry, llrz, x_hat_stage_one, z_hat_stage_one, logit_hx_perp, logit_hz_perp = decoder_soft((llr, syndrome_x, syndrome_z))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4590b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1151 882]\n",
      "[1151 882]\n"
     ]
    }
   ],
   "source": [
    "num_hx = tf.math.softplus(-1.*llrx) # I or X, both commute with X-type check\n",
    "denom_hx = tf.ragged.map_flat_values(lambda x, y: tf.math.reduce_logsumexp(-1.*tf.stack([x, y], axis=-1), axis=-1), llrz, llry)\n",
    "new_llr_z = num_hx - denom_hx\n",
    "tf.print(tf.shape(new_llr_z))\n",
    "\n",
    "num_hz = tf.math.softplus(-1.*llrz) # I or Z, both commute with Z-type check\n",
    "denom_hz = tf.ragged.map_flat_values(lambda x, y: tf.math.reduce_logsumexp(-1.*tf.stack([x, y], axis=-1), axis=-1), llrx, llry)\n",
    "new_llr_x = num_hz - denom_hz\n",
    "tf.print(tf.shape(new_llr_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e009216",
   "metadata": {},
   "outputs": [],
   "source": [
    "def osd0(llr, pcm, s):\n",
    "    # use llrz together with code.hx and syndrome_x, return noise_z_hat\n",
    "    sort_order = tf.argsort(llr)\n",
    "\n",
    "    permuted_pcm = tf.gather(pcm, sort_order, axis=1) \n",
    "\n",
    "    inv_sort = tf.math.invert_permutation(sort_order)\n",
    "    \n",
    "    row_ech_form, rank, transform, pivot_cols = row_echelon(permuted_pcm.numpy())\n",
    "    \n",
    "    new_pcm = tf.gather(permuted_pcm, pivot_cols, axis=1)\n",
    "    \n",
    "    syndrome = tf.expand_dims(s, 1)\n",
    "    \n",
    "    pcm_synd = tf.concat((new_pcm, syndrome), axis=1)\n",
    "    \n",
    "    row_ech_form, rank, _, _ = row_echelon(pcm_synd.numpy(), reduced=True)\n",
    "    \n",
    "#     tf.print(tf.shape(pivot_cols))\n",
    "#     tf.print(tf.shape(row_ech_form[:,-1]))\n",
    "    \n",
    "    e_hat = tf.tensor_scatter_nd_update(tf.zeros_like(llr, dtype=tf.bool), tf.expand_dims(pivot_cols, axis=1), row_ech_form[:,-1])\n",
    "    \n",
    "    e_hat = tf.gather(e_hat, inv_sort)\n",
    "    \n",
    "    return e_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6bfece7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[429 882]\n",
      "[429 882]\n",
      "[429 1151]\n",
      "[429 1151]\n"
     ]
    }
   ],
   "source": [
    "_, _, _, pivot_hx = row_echelon(code.hx.T)\n",
    "reduced_hx = tf.gather(code.hx, pivot_hx, axis=0) # select linearly independent rows\n",
    "tf.print(tf.shape(reduced_hx))\n",
    "\n",
    "_, _, _, pivot_hz = row_echelon(code.hz.T)\n",
    "reduced_hz = tf.gather(code.hz, pivot_hz, axis=0) # select linearly independent rows\n",
    "tf.print(tf.shape(reduced_hz))\n",
    "\n",
    "reduced_sx = tf.gather(syndrome_x, pivot_hx, axis=0)\n",
    "reduced_sz = tf.gather(syndrome_z, pivot_hz, axis=0)\n",
    "\n",
    "tf.print(tf.shape(reduced_sx))\n",
    "tf.print(tf.shape(reduced_sz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76cbda05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1151 882]\n",
      "[1151 882]\n"
     ]
    }
   ],
   "source": [
    "noise_z_hat_list, noise_x_hat_list = [], []\n",
    "bs = tf.shape(new_llr_z)[0]\n",
    "for i in range(bs):\n",
    "    noise_z_hat_list.append(osd0(new_llr_z[i], reduced_hx, reduced_sx[:,i]))\n",
    "    noise_x_hat_list.append(osd0(new_llr_x[i], reduced_hz, reduced_sz[:,i]))\n",
    "    \n",
    "noise_x_hat = tf.stack(noise_x_hat_list, axis=0)\n",
    "tf.print(tf.shape(noise_x_hat))\n",
    "noise_z_hat = tf.stack(noise_z_hat_list, axis=0)\n",
    "tf.print(tf.shape(noise_z_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecfa4bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 882 1151], shape=(2,), dtype=int32)\n",
      "tf.Tensor([ 882 1151], shape=(2,), dtype=int32)\n",
      "tf.Tensor([1151  882], shape=(2,), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "x_hat = tf.transpose(noise_x_hat, (1,0)) # [self.n, bs]\n",
    "z_hat = tf.transpose(noise_z_hat, (1,0))\n",
    "\n",
    "print(tf.shape(noise_x_T))\n",
    "print(tf.shape(x_hat))\n",
    "\n",
    "x_diff = tf.cast(tf.math.logical_xor(noise_x_T, x_hat), code.hx_perp.dtype)\n",
    "z_diff = tf.cast(tf.math.logical_xor(noise_z_T, z_hat), code.hz_perp.dtype)\n",
    "\n",
    "sx = int_mod_2(tf.matmul(code.hz, x_diff))\n",
    "sz = int_mod_2(tf.matmul(code.hx, z_diff)) \n",
    "s_hat = tf.concat([sx, sz], axis=0)\n",
    "s_hat = tf.transpose(s_hat, (1,0))\n",
    "err = tf.reduce_any(tf.not_equal(tf.zeros_like(s_hat), s_hat), axis=-1)\n",
    "# OSD should clean up all flag errors\n",
    "\n",
    "lsx = int_mod_2(tf.matmul(code.hx_perp, x_diff))\n",
    "lsz = int_mod_2(tf.matmul(code.hz_perp, z_diff))\n",
    "\n",
    "ls_hat = tf.concat([lsx, lsz], axis=0)      # for total logical error counts\n",
    "ls_hat = tf.transpose(ls_hat, (1,0))         # bs should be the first dimension!!!\n",
    "logical_err = tf.reduce_any(tf.not_equal(tf.zeros_like(ls_hat), ls_hat), axis=-1)\n",
    "\n",
    "print(tf.shape(s_hat))\n",
    "print(tf.reduce_sum(s_hat))\n",
    "print(tf.reduce_sum(tf.cast(logical_err, dtype=tf.int32)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8d47f1",
   "metadata": {},
   "source": [
    "## Quaternary BP\n",
    "| CN update       | $p$  | $p_L$  |\n",
    "| --------------- | :-:  | :-:    |\n",
    "| SP, 1.0, 64     | 0.10 | 5.1e-3\n",
    "|                 | 0.09 | 1.74e-3\n",
    "|                 | 0.08 | 1.08e-3\n",
    "| NMS, 0.8, 100   | 0.10 | 2.8e-4\n",
    "|                 | 0.09 | 2e-5 (1/50000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24bd5100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        p |    Flagged |       BLER | flag errors | block errors |  num blocks | runtime [s] |    status\n",
      "---------------------------------------------------------------------------------------------------------------------------------------\n",
      "    0.067 | 8.6010e-01 | 8.6010e-01 |        8601 |         8601 |       10000 |         2.2 |reached target block errors\n",
      "     0.06 | 6.2610e-01 | 6.2610e-01 |        6261 |         6261 |       10000 |         0.1 |reached target block errors\n",
      "    0.053 | 3.0940e-01 | 3.0940e-01 |        3094 |         3094 |       10000 |         0.1 |reached target block errors\n",
      "    0.047 | 8.1000e-02 | 8.1000e-02 |         810 |          810 |       10000 |         0.1 |reached target block errors\n",
      "     0.04 | 8.8000e-03 | 8.8000e-03 |         176 |          176 |       20000 |         0.2 |reached target block errors\n",
      "    0.033 | 5.6667e-04 | 5.6667e-04 |         102 |          102 |      180000 |         2.2 |reached target block errors\n",
      "    0.027 | 2.8571e-04 | 2.8571e-04 |         100 |          100 |      350000 |         4.3 |reached target block errors\n",
      "     0.02 | 1.9608e-04 | 1.9608e-04 |         100 |          100 |      510000 |         6.2 |reached target block errors\n",
      "    0.013 | 1.6949e-04 | 1.6949e-04 |         100 |          100 |      590000 |         7.1 |reached target block errors\n",
      "    0.007 | 7.4627e-05 | 7.4627e-05 |         100 |          100 |     1340000 |        16.2 |reached target block errors\n"
     ]
    }
   ],
   "source": [
    "code = GHP_n882_k24\n",
    "decoder = LDPCBPDecoder(code.hx, is_syndrome=True, num_iter=64) # binary syndrome BP decoder\n",
    "# noise added by BSC channel\n",
    "model = BP_BSC_Model(pcm=code.hx, decoder=decoder, logical_pcm=code.hz_perp, p0=0.2) # p0 is used to initialize BP\n",
    "# If p0 is not specified (default set to None), then the actual p value employed for noise generation will be used for BP initialization.\n",
    "p_range = np.arange(0.01,0.101,0.01)[::-1] * 2/3 \n",
    "\n",
    "ber_plot = PlotBER(\"Performance of the [[882,24]] code on BSC channel under binary decoding\")\n",
    "\n",
    "ber_plot.simulate(model, \n",
    "                  ebno_dbs=p_range, # physical error rates to simulate\n",
    "                  legend=f\"{code.name}, factor={1.0}, iter={64}, p0=0.2\", # legend string for plotting\n",
    "                  max_mc_iter=1000, # run 1000 Monte Carlo runs per physical error rate point\n",
    "                  num_target_block_errors=100, # continue with next physical error rate point after 1000 block errors\n",
    "                  batch_size=10000, # batch-size per Monte Carlo run\n",
    "                  soft_estimates=False, # the model returns hard-estimates\n",
    "                  early_stop=True, # stop simulation if no error has been detected at current physical error rate\n",
    "                  show_fig=False, # do not show the figure after all results are simulated\n",
    "                  add_bler=True, # we are interested in block error rate\n",
    "                  qldpc=True, # show flagged error rate, instead of showing bit error rate\n",
    "                  forward_keyboard_interrupt=True); # should be True in a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd95a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BP2_BSC_Error_Model(tf.keras.Model):\n",
    "    def __init__(self, pcm, decoder, logical_pcm=None, p0=None):\n",
    "\n",
    "        super().__init__()\n",
    "        \n",
    "        # store values internally\n",
    "        self.pcm = pcm\n",
    "        self.logical_pcm = logical_pcm\n",
    "        _, self.n = pcm.shape\n",
    "        self.source = BinarySource()\n",
    "       \n",
    "        self.channel = BinarySymmetricChannel()\n",
    "\n",
    "        # FEC encoder / decoder\n",
    "        self.decoder = decoder\n",
    "        self.p0 = p0\n",
    "\n",
    "#     @tf.function(jit_compile=True, reduce_retracing=True) # XLA mode during evaluation\n",
    "    @tf.function() # graph mode\n",
    "    def call(self, batch_size, ebno_db):\n",
    "\n",
    "        p0 = ebno_db if self.p0 is None else self.p0\n",
    "        llr_const = -tf.math.log((1.-p0)/p0)\n",
    "           \n",
    "        c = tf.zeros([batch_size, self.n])\n",
    "        noise = self.channel((c, ebno_db))  # [bs, self.n]\n",
    "        llr = tf.fill(tf.shape(noise), llr_const)  \n",
    "        noise_int = tf.transpose(tf.cast(noise, self.pcm.dtype), (1,0)) # [self.n, bs]\n",
    "        syndrome = int_mod_2(tf.matmul(self.pcm, noise_int))\n",
    "        noise_hat = self.decoder((llr, syndrome)) \n",
    "\n",
    "        noise_hat = tf.transpose(tf.cast(noise_hat, self.pcm.dtype), (1,0)) # [self.n, bs]\n",
    "        noise_diff = tf.math.logical_xor(tf.cast(noise_int, tf.bool), tf.cast(noise_hat, tf.bool)) \n",
    "        noise_diff = tf.cast(noise_diff, self.pcm.dtype)\n",
    "        s_hat = int_mod_2(tf.matmul(self.pcm, noise_diff))\n",
    "        s_hat = tf.transpose(s_hat, (1,0)) # bs should be the first dimension!\n",
    "\n",
    "        err = tf.reduce_any(tf.not_equal(tf.zeros_like(s_hat), s_hat), axis=-1)\n",
    "        return noise[err]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a6515dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "physical error rate 0.03999999910593033, find BP failed-to-decode samples (flagged errors)\n"
     ]
    }
   ],
   "source": [
    "GHP_n882_k24 = create_QC_GHP_codes(63, create_cyclic_permuting_matrix(7, [27,54,0]), [0,1,6]) # 18 <= d <= 24\n",
    "code = GHP_n882_k24\n",
    "\n",
    "p = tf.constant(0.04)\n",
    "num_iter = 100\n",
    "factor = tf.constant(0.8)\n",
    "\n",
    "decoder_hard = LDPCBPDecoder(code.hx, cn_type=\"minsum\", is_syndrome=True, num_iter=num_iter, normalization_factor=factor, hard_out=True) # binary syndrome BP decoder\n",
    "decoder_soft = LDPCBPDecoder(code.hx, cn_type=\"minsum\", is_syndrome=True, num_iter=num_iter, normalization_factor=factor, hard_out=False) # binary syndrome BP decoder\n",
    "\n",
    "model = BP2_BSC_Error_Model(pcm=code.hx, decoder=decoder_hard, p0=p)\n",
    "\n",
    "batch_size = tf.constant(50000)\n",
    "\n",
    "print(f\"physical error rate {p}, find BP failed-to-decode samples (flagged errors)\")\n",
    "\n",
    "sample_list = []\n",
    "\n",
    "noise = model(batch_size, p)\n",
    "sample_list.append(noise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c45047d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1190 882]\n",
      "[441 1190]\n"
     ]
    }
   ],
   "source": [
    "noise = sample_list[0]\n",
    "tf.print(tf.shape(noise))\n",
    "noise_T = tf.transpose(noise, (1,0))\n",
    "noise_int = tf.cast(noise_T, code.hx.dtype)\n",
    "syndrome = int_mod_2(tf.matmul(code.hx, noise_int))\n",
    "tf.print(tf.shape(syndrome))\n",
    "\n",
    "llr = tf.fill(tf.shape(noise), -tf.math.log((1.-p)/p))\n",
    "llr_post = decoder_soft((llr, syndrome))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "28789edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[429 882]\n",
      "[429 1190]\n",
      "[1190 882]\n"
     ]
    }
   ],
   "source": [
    "_, _, _, pivot_hx = row_echelon(code.hx.T)\n",
    "reduced_hx = tf.gather(code.hx, pivot_hx, axis=0) # select linearly independent rows\n",
    "tf.print(tf.shape(reduced_hx))\n",
    "\n",
    "reduced_s = tf.gather(syndrome, pivot_hx, axis=0)\n",
    "\n",
    "tf.print(tf.shape(reduced_s))\n",
    "\n",
    "noise_hat_list = []\n",
    "bs = tf.shape(llr_post)[0]\n",
    "for i in range(bs):\n",
    "    noise_hat_list.append(osd0(-1.*llr_post[i], reduced_hx, reduced_s[:,i]))\n",
    "    \n",
    "noise_hat = tf.stack(noise_hat_list, axis=0)\n",
    "tf.print(tf.shape(noise_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "520cc590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 882 1190], shape=(2,), dtype=int32)\n",
      "tf.Tensor([ 882 1190], shape=(2,), dtype=int32)\n",
      "tf.Tensor([1190  441], shape=(2,), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "noise_hat = tf.transpose(noise_hat, (1,0)) # [self.n, bs]\n",
    "print(tf.shape(noise_T))\n",
    "print(tf.shape(noise_hat))\n",
    "noise_diff = tf.cast(tf.math.logical_xor(tf.cast(noise_T, tf.bool), noise_hat), code.hz_perp.dtype)\n",
    "\n",
    "s_hat = int_mod_2(tf.matmul(code.hx, noise_diff)) \n",
    "s_hat = tf.transpose(s_hat, (1,0))\n",
    "err = tf.reduce_any(tf.not_equal(tf.zeros_like(s_hat), s_hat), axis=-1)\n",
    "# OSD should clean up all flag errors\n",
    "\n",
    "ls_hat = int_mod_2(tf.matmul(code.hz_perp, noise_diff))\n",
    "\n",
    "ls_hat = tf.transpose(ls_hat, (1,0))         # bs should be the first dimension!!!\n",
    "logical_err = tf.reduce_any(tf.not_equal(tf.zeros_like(ls_hat), ls_hat), axis=-1)\n",
    "\n",
    "print(tf.shape(s_hat))\n",
    "print(tf.reduce_sum(s_hat))\n",
    "print(tf.reduce_sum(tf.cast(logical_err, dtype=tf.int32)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2961e27e",
   "metadata": {},
   "source": [
    "## Binary BP\n",
    "| CN update       | $p$  | $p_L$  |\n",
    "| --------------- | :-:  | :-:    |\n",
    "| NMS, 0.8, 100   | 0.05 | 6.4e-4\n",
    "| ^^              | 0.04 | 2e-5 (1/50000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
